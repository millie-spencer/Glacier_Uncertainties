{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546609a9-0940-419c-ae28-cac52ea2ec11",
   "metadata": {},
   "source": [
    "# Figure 9: Hydro projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from   plotly.subplots import make_subplots\n",
    "\n",
    "os.chdir('/home/rooda/OGGM_results/')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eda580-9ab5-4832-8a0e-27a9efbf7d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocessing(ds, scenario): # clean dataframe\n",
    "    ds = ds.to_dataframe()\n",
    "    ds[\"scenario\"] = scenario\n",
    "    ds = ds.set_index(\"scenario\", append=True)\n",
    "    ds = ds.reorder_levels(['scenario', 'rgi_id', 'time'])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8ce5-9cae-42de-8be3-873b622cdc37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e685250e-066f-46db-889e-17af3b381bac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bcd9c-e6ef-47c9-9554-5b6ebcc9baa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins = gpd.read_file(\"zip:////home/rooda/Dropbox/Patagonia/MS2 Results/zenodo/basins_boundaries.zip\")\n",
    "basins = basins[[\"basin_id\", \"basin_zone\", \"basin_name\", \"geometry\"]].set_index(\"basin_id\")\n",
    "basins['basin_name']= basins['basin_name'].replace({'Santa Cruz': 'Santa Cruz                        '})\n",
    "\n",
    "area = pd.read_csv(\"/home/rooda/Dropbox/Patagonia/MS2 Results/zenodo/dataset_historical.csv\", index_col = \"basin_id\").area_RGI6\n",
    "basins = pd.concat([basins, area], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f65d02-f439-4921-aa36-ccf1f44aca96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# historical\n",
    "ts_hist = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_historical.nc\")[[\"melt_on_glacier\"]]\n",
    "ids     = basins[basins.index.isin(ts_hist.rgi_id.to_pandas().tolist())]\n",
    "ts_hist = ts_hist.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "ts_hist = ts_hist.isel(time = slice(0, -1)) \n",
    "ts_hist = ts_hist.groupby('rgi_id').sum() \n",
    "ts_hist_t = ts_hist.sum(dim = \"rgi_id\").assign_coords({\"rgi_id\": \"total\"}).expand_dims('rgi_id')\n",
    "ts_hist = xr.concat([ts_hist, ts_hist_t], dim = \"rgi_id\")\n",
    "\n",
    "ts_hist_var  = postprocessing(ts_hist.std(dim=\"options\"),  \"historical\")\n",
    "ts_hist_mean = postprocessing(ts_hist.mean(dim=\"options\"), \"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5170c49-6c22-4412-8f50-aadf0a085648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# future\n",
    "scenarios        = [\"ct_random\", \"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"]\n",
    "\n",
    "ts_future_mean = []\n",
    "ts_future_var  = []\n",
    "\n",
    "for scenario in tqdm(scenarios): \n",
    "    ts_future_ssp   = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_future_{}.nc\".format(scenario))[[\"melt_on_glacier\"]]\n",
    "    ids             = basins[basins.index.isin(ts_future_ssp.rgi_id.to_pandas().tolist())]\n",
    "    ts_future_ssp   = ts_future_ssp.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "    \n",
    "    if scenario == \"ct_random\":\n",
    "        ts_future_ssp = ts_future_ssp.rolling(time=10, center=True, min_periods = 5).mean()\n",
    "    \n",
    "    ts_future_ssp   = ts_future_ssp.groupby('rgi_id').sum()\n",
    "    ts_future_ssp_t = ts_future_ssp.sum(dim = \"rgi_id\").assign_coords({\"rgi_id\": \"total\"}).expand_dims('rgi_id')\n",
    "    ts_future_ssp   = xr.concat([ts_future_ssp, ts_future_ssp_t], dim = \"rgi_id\")\n",
    "    \n",
    "    ts_future_var.append(postprocessing(ts_future_ssp.std(dim=\"options\"),   scenario))\n",
    "    ts_future_mean.append(postprocessing(ts_future_ssp.mean(dim=\"options\"), scenario))\n",
    "\n",
    "ts_future_var  = pd.concat(ts_future_var)\n",
    "ts_future_mean = pd.concat(ts_future_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc2318-20bc-4289-9a65-fdd9784eddef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concat historical and future perios\n",
    "ts_var  = pd.concat([ts_hist_var,  ts_future_var]).reset_index()\n",
    "ts_mean = pd.concat([ts_hist_mean, ts_future_mean]).reset_index()\n",
    "\n",
    "dict_replace = {\"scenario\": {\"historical\":'Historical', \n",
    "                             \"ct_random\":'Commitment run', \n",
    "                             \"ssp126\":'SSP 1-2.6', \n",
    "                             \"ssp245\":'SSP 2-4.5',\n",
    "                             \"ssp370\":'SSP 3-7.0', \n",
    "                             \"ssp585\":'SSP 5-8.5'}}\n",
    "\n",
    "ts_var      = ts_var.replace(dict_replace)\n",
    "ts_mean     = ts_mean.replace(dict_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090abc0-4f45-4b7a-b252-4508c8f28895",
   "metadata": {},
   "source": [
    "### Peak water year for each catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0f015-bfe3-4ee2-8954-a272d1b6eec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# historical period\n",
    "all_combs = pd.read_csv(\"/home/rooda/Dropbox/Patagonia/MS2 Results/dataset_hydro_signatures.csv\", index_col = 0)\n",
    "all_combs = all_combs.loc[\"peak_water_year\"]\n",
    "all_combs = all_combs.loc[all_combs.Variable == \"melt_on_glacier\"]\n",
    "all_combs = all_combs.mean(axis = 0, skipna = True, numeric_only = True)\n",
    "all_combs = all_combs.astype(\"int64\").rename(\"peak_water_year\")\n",
    "all_combs.index = all_combs.index.astype(\"int64\")\n",
    "\n",
    "basins = pd.merge(basins, all_combs, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512f45a-169b-4ee0-9702-874cd276a601",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efc0d8-63a1-42fa-8df4-686fe8c78727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basemap for background\n",
    "geo_map = gpd.read_file(\"/home/rooda/Dropbox/ArcGIS/Chile/south_america.shp\")\n",
    "geo_map = geo_map[(geo_map.CC == \"CI\") | (geo_map.CC == \"AR\")]\n",
    "geo_map = geo_map.dissolve(by='REGION')\n",
    "geo_map[\"geometry\"] = geo_map.simplify(0.01)\n",
    "\n",
    "poly_gdf = shapely.geometry.Polygon([(-76, -55.7), (-76, -40.52), (-68.05, -40.52), (-68.05, -55.7), (-76, -55.8)])\n",
    "poly_gdf = gpd.GeoDataFrame([1], geometry=[poly_gdf], crs=geo_map.crs)\n",
    "\n",
    "geo_map = geo_map.clip(poly_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe7259-0815-4e84-b4cc-19abbdb788b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydrological zone divides\n",
    "geo_lines = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Basins_Patagonia_ice_divides.shp\")\n",
    "\n",
    "lats = []\n",
    "lons = []\n",
    "\n",
    "for feature in geo_lines.geometry:\n",
    "    if isinstance(feature, shapely.geometry.linestring.LineString):\n",
    "        linestrings = [feature]\n",
    "    elif isinstance(feature, shapely.geometry.multilinestring.MultiLineString):\n",
    "        linestrings = feature.geoms\n",
    "    else:\n",
    "        continue\n",
    "    for linestring in linestrings:\n",
    "        x, y = linestring.xy\n",
    "        lats = np.append(lats, y)\n",
    "        lons = np.append(lons, x)\n",
    "        lats = np.append(lats, None)\n",
    "        lons = np.append(lons, None)\n",
    "        \n",
    "lat_coords = [-43.2, -45.95,  -46.4,  -47.55,  -49.2,   -50.5,   -52.0, -53.1, -54.8]\n",
    "lon_coords = [-71.2, -71.7,   -74.5,  -71.7,   -72.2,   -72.3,   -72.1, -71.7, -68.9]\n",
    "names      = [\"PPY\", \"PCA\", \"NPI-W\", \"NPI-E\", \"SPI-N\", \"SPI-C\", \"SPI-S\", \"GCN\", \"CDI\"]\n",
    "names  = ['<b>'+x+'</b>' for x in names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907b6a2-98b6-44f1-a111-e56b85ddfce5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81749ae5-4ef1-4b88-b232-44b25296fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = px.colors.colorbrewer.RdYlBu\n",
    "\n",
    "scenarios   = [\"Historical\", \"Commitment run\", \"SSP 1-2.6\", \"SSP 2-4.5\", \"SSP 3-7.0\", \"SSP 5-8.5\"]\n",
    "scen_colors = {\"Historical\":\"rgba(0, 0, 0, 0.8)\", \n",
    "               \"Commitment run\":\"rgba(0, 0, 0, 0.5)\", \n",
    "               \"SSP 1-2.6\":cl[9], \n",
    "               \"SSP 2-4.5\":cl[8], \n",
    "               \"SSP 3-7.0\":cl[3],\n",
    "               \"SSP 5-8.5\":cl[1]}\n",
    "\n",
    "shaded_colors = {\"Historical\":\"rgba(0, 0, 0, 0.1)\", \n",
    "                 \"SSP 1-2.6\": \"rgba(49,54,149, 0.1)\", \n",
    "                 \"SSP 5-8.5\": \"rgba(215,48,39,0.1)\"}\n",
    "\n",
    "zone1  = ['PPY', 'PCA']\n",
    "zone2  = ['NPI-E','NPI-W']\n",
    "zone3  = ['SPI-N', 'SPI-C', 'SPI-S']\n",
    "zone4  = ['GCN', 'CDI']\n",
    "\n",
    "fig    = make_subplots(rows=3, cols=3, horizontal_spacing = 0.03, vertical_spacing = 0.05, \n",
    "                       shared_xaxes= True, shared_yaxes= False, subplot_titles = [\"Peak water ensemble mean\", \"Glacier melt (m<sup>3</sup> s<sup>-1</sup>)\"],\n",
    "                       specs=[[{\"type\": \"scattergeo\", \"rowspan\": 3},  {\"type\": \"xy\", \"colspan\": 2},           None],\n",
    "                              [ None,                         {\"type\": \"xy\"},               {\"type\": \"xy\"}],\n",
    "                              [ None,                         {\"type\": \"xy\"},               {\"type\": \"xy\"}]])\n",
    "\n",
    "fig.add_trace(go.Choropleth(geojson = eval(geo_map['geometry'].to_json()),  locations = geo_map.index, z = geo_map['iso_num'], \n",
    "                            colorscale = [\"#EAEAF2\", \"#EAEAF2\"], showscale= False, marker_line_color ='white', marker_line_width=0.1), row=1, col=1)\n",
    "\n",
    "colorbar_volume = dict(len=0.45, x=0.2, y= 0.77, title='Year', thickness=20, tickwidth=1, title_font =  dict(size = 12))\n",
    "fig.add_trace(go.Choropleth(geojson = eval(basins['geometry'].to_json()),  locations = basins.index, z = basins['peak_water_year'], \n",
    "                            colorscale = [(0., cl[2]),(0.4, \"#ffe9ba\"),(1, cl[9])], marker_line_color ='white', marker_line_width=0.1, \n",
    "                            zmin = 1980, zmax = 2080, colorbar = colorbar_volume), row=1, col=1)\n",
    "fig.add_annotation(text=\"(a)\", font=dict(size=16), x=0.01, y=0.995,  xref = \"paper\", yref = \"paper\", showarrow=False)\n",
    "\n",
    "## Add basin and hydrological zone names plus the hydro zone divides\n",
    "fig.add_trace(go.Scattergeo(lon = lons, lat = lats, mode = 'lines', line = dict(width = 0.8, color = 'black'), opacity = 0.7, showlegend = False),row=1, col=1)  \n",
    "fig.add_trace(go.Scattergeo(lon = lon_coords, lat=lat_coords, mode='text', text=names, textfont=dict(size=12, color = \"rgba(0,0,0,0.7)\"), showlegend = False),row=1, col=1)\n",
    "fig.add_scattergeo(geojson = eval(basins['geometry'].to_json()), locations = basins.index, text = basins['basin_name'], mode = 'text', showlegend = False,\n",
    "                   textfont=dict(size=11, color = \"rgba(0,0,0,0.3)\"),row=1, col=1)\n",
    "\n",
    "fig.update_geos(showframe = True, framewidth = 1,  framecolor = \"black\", lonaxis_range=[-76, -68], lataxis_range=[-55.8, -40.5], \n",
    "                bgcolor = \"#f9f9f9\", showland = False, showcoastlines = False, showlakes = False)\n",
    "\n",
    "for t in range(0,6): # for each scenario \n",
    "    \n",
    "    # total volume\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id == \"total\"][ts_mean.scenario == scenarios[t]]\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id == \"total\"][ts_var.scenario == scenarios[t]]    \n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=True, legendgroup=t), row=1, col=2)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=1, col=2)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=1, col=2)\n",
    "    fig.add_annotation(text=\"(b) Total\", font = dict(size = 13), x = 1985, y = 1150, showarrow=False, row=1, col=2)\n",
    "    fig.update_yaxes(range = [1000,3500], dtick = 1000, row = 1, col =2)\n",
    "                     \n",
    "    # zone 1\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id.isin(zone1)][ts_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id.isin(zone1)][ts_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=2, col=2)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=2, col=2)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=2, col=2)\n",
    "    fig.add_annotation(text=\"(c) PPY + PCA\", font = dict(size = 13), x = 2000, y = 8, showarrow=False, row=2, col=2)\n",
    "    fig.update_yaxes(range = [0,120], row = 2, col =2)\n",
    "    \n",
    "    # zone 2\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id.isin(zone2)][ts_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id.isin(zone2)][ts_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=2, col=3)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=2, col=3)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=2, col=3)\n",
    "    fig.add_annotation(text=\"(d) NPI\", font = dict(size = 13), x = 1990, y = 220, showarrow=False, row=2, col=3)\n",
    "    fig.update_yaxes(range = [200,599], row = 2, col = 3)\n",
    "    \n",
    "    # zone 3\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id.isin(zone3)][ts_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id.isin(zone3)][ts_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=3, col=2)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=3, col=2)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=3, col=2)\n",
    "    fig.add_annotation(text=\"(e) SPI\", font = dict(size = 13), x = 1990, y = 600, showarrow=False, row=3, col=2)\n",
    "    fig.update_yaxes(range = [500,2000], row = 3, col = 2)\n",
    "    \n",
    "    # zone 4\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id.isin(zone4)][ts_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id.isin(zone4)][ts_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=3, col=3)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=3, col=3)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=3, col=3)\n",
    "    fig.add_annotation(text=\"(f) GCN + CDI\", font = dict(size = 13), x = 1998, y = 60, showarrow=False, row=3, col=3)\n",
    "    fig.update_yaxes(range = [50,250], row = 3, col = 3)\n",
    "    \n",
    "fig.update_xaxes(griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", zeroline=False, showline = True, linecolor = 'black', linewidth = 1, ticks=\"outside\", mirror=True)\n",
    "fig.update_yaxes(griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", zeroline=True,  showline = True, linecolor = 'black', linewidth = 1, ticks=\"outside\", mirror=True)    \n",
    "    \n",
    "fig.update_yaxes(tickangle = -90)\n",
    "fig.update_xaxes(dtick = 20)\n",
    "fig.update_layout(legend=dict(yanchor=\"top\", y=1.0, orientation = \"h\", xanchor=\"left\", x=0.34, tracegroupgap = 2, bgcolor = 'rgba(0,0,0,0.0)'))\n",
    "fig.update_layout(width = 1000, template = \"seaborn\", height = 600, margin = dict(l=20, r=20, b=20, t=20))\n",
    "\n",
    "fig.write_image(\"/home/rooda/Dropbox/Patagonia/MS2 Results/Figure_9_hydro_projection.png\", scale=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc47eb4-99ee-49f6-a363-cec87ae4e55a",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83f988-641d-420f-bd12-190d033251a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# peak water\n",
    "\n",
    "pw_ds = pd.read_csv(\"/home/rooda/Dropbox/Patagonia/MS2 Results/dataset_hydro_signatures.csv\", index_col = 0)\n",
    "pw_ds = pw_ds.loc[\"peak_water_year\"]\n",
    "pw_ds = pw_ds.loc[pw_ds.Variable == \"melt_on_glacier\"]\n",
    "\n",
    "area  = basins.loc[pw_ds.columns[7:].astype(\"int64\")].area_RGI6\n",
    "pw_ds = ((pw_ds.iloc[:,7:] <= 2020) * area.to_numpy()).sum(axis = 1)\n",
    "pw_ds = pw_ds * 100 / area.sum()\n",
    "\n",
    "\"{:.0f}% ± {:.0f}% of the catchment glacier area has already peaked in terms of glacier melt (year 2020)\".format(\n",
    "    pw_ds.mean(), pw_ds.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e5338-71c7-4b9a-bdaa-90b40308abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total glacier melt in ref period\n",
    "\n",
    "ts_hist = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_historical.nc\").melt_on_glacier\n",
    "ts_hist = ts_hist.sum(dim = \"rgi_id\").sel(time = slice(1980,2015))\n",
    "ts_hist = ts_hist.mean(dim = \"time\")\n",
    "\n",
    "\"The total glacier melt for the study domain on glacier in the reference period (1980–2015) was {} ± {} m3 s-1\".format(\n",
    "    int(ts_hist.mean()), int(ts_hist.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b10d0-36af-41b6-a7f7-905f7dd04986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# contribution in % by zone\n",
    "ts_hist = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_historical.nc\").melt_on_glacier\n",
    "ts_hist = ts_hist.sel(time = slice(1980,2015))\n",
    "ts_hist = ts_hist.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "ts_hist = ts_hist.groupby('rgi_id').sum()\n",
    "ts_hist = ts_hist.mean(dim =[\"time\", \"options\"])\n",
    "\n",
    "\"the northern area (PPY and PCA), NPI, SPI and the southern area (CGN and CDI) contributed with {:.1f}%, {:.1f}%, {:.1f}% and {:.1f}%\".format(\n",
    "    ts_hist.sel(rgi_id = ts_hist.rgi_id.isin([\"PPY\", \"PCA\"])).sum() * 100 / ts_hist.sum(), \n",
    "    ts_hist.sel(rgi_id = ts_hist.rgi_id.isin([\"NPI-W\", \"NPI-E\"])).sum() * 100 / ts_hist.sum(),\n",
    "    ts_hist.sel(rgi_id = ts_hist.rgi_id.isin([\"SPI-N\", \"SPI-C\", \"SPI-S\"])).sum() * 100 / ts_hist.sum(),\n",
    "    ts_hist.sel(rgi_id = ts_hist.rgi_id.isin([\"GCN\", \"CDI\"])).sum() * 100 / ts_hist.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a427fb-749c-467a-b357-e6ad26be5d4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total glacier melt by ssp in the future (2070-2099)\n",
    "ts_future = xr.open_mfdataset(\"/home/rooda/OGGM_results/runs/OGGM_future_ssp*.nc\").melt_on_glacier\n",
    "ts_future = ts_future.sel(time = slice(2070,2100)).sum(dim = \"rgi_id\").load()\n",
    "\n",
    "\"the mean glacier melt on glacier in 2070–2099 varies from {} ± {} m3 s-1 in SSP 1-2.6 to {} ± {} m3 s-1 in SSP 5-8.5\".format(\n",
    "    int(ts_future.sel(options = \"ssp126\").mean(dim = \"time\").mean(dim = \"options\")), \n",
    "    int(ts_future.sel(options = \"ssp126\").mean(dim = \"time\").std(dim = \"options\")),\n",
    "    int(ts_future.sel(options = \"ssp585\").mean(dim = \"time\").mean(dim = \"options\")),\n",
    "    int(ts_future.sel(options = \"ssp585\").mean(dim = \"time\").std(dim = \"options\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3ab29-0501-4abe-8fd5-79283e49e8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
