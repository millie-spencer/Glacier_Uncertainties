{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546609a9-0940-419c-ae28-cac52ea2ec11",
   "metadata": {},
   "source": [
    "# Figure 9: Hydro projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from oggm import utils\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from   plotly.subplots import make_subplots\n",
    "\n",
    "cl     = px.colors.qualitative.D3\n",
    "os.chdir('/home/rooda/OGGM_results/')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8ce5-9cae-42de-8be3-873b622cdc37",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ids for each glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bcd9c-e6ef-47c9-9554-5b6ebcc9baa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Catchment shapefiles\n",
    "basins = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Basins_Patagonia_ice.shp\")\n",
    "basins = basins.set_index(\"ID\")\n",
    "\n",
    "names = [\"Yelcho\", \"Baker\", \"Santa Cruz                        \", \"Palena\", \"Grey\", \"Puelo\", \"Cisnes\", \"Aysen\", \"Pascua\"] \n",
    "basins.loc[basins.basin_area > 5000, \"Name\"] = names # the space is important due to visualization purposes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f65d02-f439-4921-aa36-ccf1f44aca96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Glacier shapefiles\n",
    "RGI6_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI6_ids = RGI6_ids[RGI6_ids.area_km2 > 7][[\"RGIId\", \"Zone\", \"ID_basin\"]]\n",
    "\n",
    "RGI7_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI7_v2.shp\")\n",
    "RGI7_ids = RGI7_ids[RGI7_ids.area_km2 > 7]\n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'Zone' : 'Zone', 'ID_basin' : 'ID_basin'})\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"Zone\", \"ID_basin\"]]\n",
    "\n",
    "# merge both datasets\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")\n",
    "dict_zone = {1:'PPY', 2:'PCA', 3:'NPI-E', 4:'NPI-W', 5:'SPI-N', 6:'SPI-C', 7:'SPI-S', 8:'GCN', 9:'CDI'}\n",
    "ids = ids.replace({\"Zone\": dict_zone})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eda580-9ab5-4832-8a0e-27a9efbf7d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# variables to analize\n",
    "variables        = ['melt_off_glacier', 'melt_on_glacier', 'liq_prcp_off_glacier', 'liq_prcp_on_glacier']\n",
    "scenarios        = [\"ct_random\", \"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\"]\n",
    "\n",
    "def preprocessing(ds): # remove unnecessary variables and coordinates\n",
    "    return ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])[variables]\n",
    "\n",
    "def hydro_variables(ds): # calculate total_runoff, melt_on_glacier and smb\n",
    "    ds[\"total_runoff\"] = ((ds.melt_off_glacier + ds.melt_on_glacier + ds.liq_prcp_off_glacier + ds.liq_prcp_on_glacier)*1e-3)/(365*86400) # m3/s\n",
    "    ds[\"melt_on_glacier\"] = ((ds.melt_on_glacier)*1e-3)/(365*86400) # m3/s\n",
    "    ds[\"ratio\"] = ds[\"melt_on_glacier\"] / ds[\"total_runoff\"]\n",
    "    return ds[variables]\n",
    "\n",
    "def postprocessing(ds, scenario): # clean dataframe\n",
    "    ds = ds.to_dataframe()\n",
    "    ds[\"scenario\"] = scenario\n",
    "    ds = ds.set_index(\"scenario\", append=True)\n",
    "    ds = ds.reorder_levels(['scenario', 'rgi_id', 'time'])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772d491-7e38-4bb9-af38-570724f1e90f",
   "metadata": {},
   "source": [
    "## Time series for each zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c22763-3843-43fc-99b2-d7d61c114e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# historical period\n",
    "all_combs = glob(\"/home/rooda/OGGM_results/new/*/run_outputs_*.nc\", recursive = True)\n",
    "all_opts   = xr.open_mfdataset(all_combs, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocessing)\n",
    "\n",
    "# assing zone to each glacier and aggregate the result \n",
    "ids_subset = ids[ids.index.isin(all_opts.rgi_id.to_pandas().tolist())]\n",
    "all_opts   = all_opts.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "all_opts   = all_opts.groupby('rgi_id').sum()\n",
    "all_opts   = all_opts.chunk(\"auto\")\n",
    "\n",
    "all_opts_total = all_opts.sum(dim = \"rgi_id\").assign_coords({\"rgi_id\": \"total\"}).expand_dims('rgi_id')\n",
    "all_opts  = xr.concat([all_opts, all_opts_total], dim = \"rgi_id\")\n",
    "all_opts  = hydro_variables(all_opts)\n",
    "all_opts  = all_opts.isel(time = slice(0, -1))\n",
    "\n",
    "# mean and standard desviation for each zone \n",
    "dataset_mean_hist = all_opts.mean(dim=\"options\")\n",
    "dataset_mean_hist = postprocessing(dataset_mean_hist, \"historical\")\n",
    "\n",
    "dataset_var_hist = all_opts.std(dim=\"options\")\n",
    "dataset_var_hist = postprocessing(dataset_var_hist, \"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0e584-0569-401f-a8af-ff5e22de5b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_mean = []\n",
    "dataset_var  = []\n",
    "\n",
    "for scenario in tqdm(scenarios): \n",
    "    all_combs = glob(\"/home/rooda/OGGM_results/new/*/run_output_*\"+ scenario +\"*.nc\", recursive = True)\n",
    "    all_opts   = xr.open_mfdataset(all_combs, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocessing)\n",
    "\n",
    "    if scenario == \"ct_random\":\n",
    "        all_opts[\"time\"] = all_opts[\"time\"] + 2020\n",
    "    \n",
    "    # assing zone to each glacier and aggregate the result \n",
    "    ids_subset = ids[ids.index.isin(all_opts.rgi_id.to_pandas().tolist())]\n",
    "    all_opts   = all_opts.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "    all_opts   = all_opts.groupby('rgi_id').sum()\n",
    "    all_opts_total = all_opts.sum(dim = \"rgi_id\").assign_coords({\"rgi_id\": \"total\"}).expand_dims('rgi_id')\n",
    "    all_opts   = xr.concat([all_opts, all_opts_total], dim = \"rgi_id\")\n",
    "    \n",
    "    all_opts  = hydro_variables(all_opts)\n",
    "    all_opts  = all_opts.chunk(\"auto\")\n",
    "    all_opts  = all_opts.isel(time = slice(0, -1))\n",
    "    \n",
    "    # standard desviation\n",
    "    all_opts_var = all_opts.std(dim=\"options\")\n",
    "    all_opts_var = postprocessing(all_opts_var, scenario)\n",
    "    dataset_var.append(all_opts_var)\n",
    "    \n",
    "    # mean\n",
    "    all_opts_mean = all_opts.mean(dim=\"options\")\n",
    "    all_opts_mean = postprocessing(all_opts_mean, scenario)\n",
    "    dataset_mean.append(all_opts_mean)\n",
    "    \n",
    "dataset_mean = pd.concat(dataset_mean)\n",
    "dataset_var  = pd.concat(dataset_var)\n",
    "\n",
    "dataset_var  = pd.concat([dataset_var_hist, dataset_var]).reset_index()\n",
    "dataset_mean = pd.concat([dataset_mean_hist, dataset_mean]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a339a0-bc20-433a-a1c6-acdbc7cef6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_replace = {\"scenario\": {\"historical\":'Historical', \n",
    "                             \"ct_random\":'Commitment run', \n",
    "                             \"ssp126\":'SSP 126', \n",
    "                             \"ssp245\":'SSP 245', \n",
    "                             \"ssp370\":'SSP 370', \n",
    "                             \"ssp585\":'SSP 585'}}\n",
    "\n",
    "dataset_mean = dataset_mean.replace(dict_replace)\n",
    "dataset_var  = dataset_var.replace(dict_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5090abc0-4f45-4b7a-b252-4508c8f28895",
   "metadata": {},
   "source": [
    "## Peak water year for each catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abdabc-2eb9-4fcd-a402-e8e651466b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# historical period\n",
    "all_combs = pd.read_csv(\"/home/rooda/Dropbox/Patagonia/MS2 Results/dataset_hydro_signatures.csv\", index_col = 0)\n",
    "all_combs = all_combs.loc[\"peak_water_year\"]\n",
    "all_combs = all_combs.mean(axis = 0, skipna = True, numeric_only = True)\n",
    "all_combs = all_combs.astype(\"int64\")\n",
    "\n",
    "all_combs = all_combs.rename(\"peak_water_year\") \n",
    "all_combs.index = all_combs.index.astype(\"int64\")\n",
    "\n",
    "basins = pd.merge(basins, all_combs, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efc0d8-63a1-42fa-8df4-686fe8c78727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basemap for background\n",
    "geo_map = gpd.read_file(\"/home/rooda/Dropbox/ArcGIS/Chile/south_america.shp\")\n",
    "geo_map = geo_map[(geo_map.CC == \"CI\") | (geo_map.CC == \"AR\")]\n",
    "geo_map = geo_map.dissolve(by='REGION')\n",
    "geo_map[\"geometry\"] = geo_map.simplify(0.01)\n",
    "\n",
    "poly_gdf = shapely.geometry.Polygon([(-76, -55.7), (-76, -40.52), (-68.05, -40.52), (-68.05, -55.7), (-76, -55.8)])\n",
    "poly_gdf = gpd.GeoDataFrame([1], geometry=[poly_gdf], crs=geo_map.crs)\n",
    "\n",
    "geo_map = geo_map.clip(poly_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe7259-0815-4e84-b4cc-19abbdb788b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydrological zone divides\n",
    "geo_lines = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Basins_Patagonia_ice_divides.shp\")\n",
    "\n",
    "lats = []\n",
    "lons = []\n",
    "\n",
    "for feature in geo_lines.geometry:\n",
    "    if isinstance(feature, shapely.geometry.linestring.LineString):\n",
    "        linestrings = [feature]\n",
    "    elif isinstance(feature, shapely.geometry.multilinestring.MultiLineString):\n",
    "        linestrings = feature.geoms\n",
    "    else:\n",
    "        continue\n",
    "    for linestring in linestrings:\n",
    "        x, y = linestring.xy\n",
    "        lats = np.append(lats, y)\n",
    "        lons = np.append(lons, x)\n",
    "        lats = np.append(lats, None)\n",
    "        lons = np.append(lons, None)\n",
    "        \n",
    "lat_coords = [-43.2, -45.95,  -46.4,  -47.55,  -49.2,   -50.5,   -52.0, -53.1, -54.8]\n",
    "lon_coords = [-71.2, -71.7,   -74.5,  -71.7,   -72.2,   -72.3,   -72.1, -71.7, -68.9]\n",
    "names      = [\"PPY\", \"PCA\", \"NPI-W\", \"NPI-E\", \"SPI-N\", \"SPI-C\", \"SPI-S\", \"GCN\", \"CDI\"]\n",
    "names  = ['<b>'+x+'</b>' for x in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81749ae5-4ef1-4b88-b232-44b25296fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios   = [\"Historical\", \"Commitment run\", \"SSP 126\", \"SSP 245\", \"SSP 370\", \"SSP 585\"]\n",
    "scen_colors = {\"Historical\":\"rgba(0, 0, 0, 0.8)\", \"Commitment run\":\"rgba(0, 0, 0, 0.5)\", \"SSP 126\":cl[0], \"SSP 245\":cl[2], \"SSP 370\":cl[1], \"SSP 585\":cl[3]}\n",
    "\n",
    "zone1  = ['PPY', 'PCA']\n",
    "zone2  = ['NPI-E','NPI-W']\n",
    "zone3  = ['SPI-N', 'SPI-C', 'SPI-S']\n",
    "zone4  = ['GCN', 'CDI']\n",
    "\n",
    "fig    = make_subplots(rows=3, cols=3, horizontal_spacing = 0.04, vertical_spacing = 0.05, \n",
    "                       shared_xaxes= True, shared_yaxes= False, subplot_titles = [\"Peak water ensemble mean\", \"Melt on glacier evolution (m<sup>3</sup> s<sup>-1</sup>)\"],\n",
    "                       specs=[[{\"type\": \"scattergeo\", \"rowspan\": 3},  {\"type\": \"xy\", \"colspan\": 2},           None],\n",
    "                              [ None,                         {\"type\": \"xy\"},               {\"type\": \"xy\"}],\n",
    "                              [ None,                         {\"type\": \"xy\"},               {\"type\": \"xy\"}]])\n",
    "\n",
    "fig.add_trace(go.Choropleth(geojson = eval(geo_map['geometry'].to_json()),  locations = geo_map.index, z = geo_map['iso_num'], \n",
    "                            colorscale = [\"rgba(213,213,213,0.6)\", \"rgba(213,213,213,0.6)\"], showscale= False, marker_line_color ='white', marker_line_width=0.1), row=1, col=1)\n",
    "\n",
    "colorbar_volume = dict(len=0.45, x=0.2, y= 0.77, title='Year', thickness=20, title_font =  dict(size = 12))\n",
    "fig.add_trace(go.Choropleth(geojson = eval(basins['geometry'].to_json()),  locations = basins.index, z = basins['peak_water_year'], \n",
    "                            colorscale = [(0.,\"#fe7e0d\"),(0.4, \"#ffe9ba\"),(1, \"#1d78b4\")], marker_line_color ='white', marker_line_width=0.1, \n",
    "                            zmin = 1980, zmax = 2080, colorbar = colorbar_volume), row=1, col=1)\n",
    "fig.add_annotation(text=\"a)\", font=dict(size=16), x=0.005, y=0.995,  xref = \"paper\", yref = \"paper\", showarrow=False)\n",
    "\n",
    "## Add basin and hydrological zone names plus the hydro zone divides\n",
    "fig.add_trace(go.Scattergeo(lon = lons, lat = lats, mode = 'lines', line = dict(width = 0.7,color = 'black'),opacity = 0.5, showlegend = False),row=1, col=1)  \n",
    "fig.add_trace(go.Scattergeo(lon = lon_coords, lat=lat_coords, mode='text', text=names, textfont=dict(size=12, color = \"rgba(0,0,0,0.5)\"), showlegend = False),row=1, col=1)\n",
    "fig.add_scattergeo(geojson = eval(basins['geometry'].to_json()), locations = basins.index, text = basins['Name'], mode = 'text', showlegend = False,\n",
    "                   textfont=dict(size=11, color = \"rgba(0,0,0,0.3)\"),row=1, col=1)\n",
    "\n",
    "fig.update_geos(showframe = True, framewidth = 1,  framecolor = \"black\", lonaxis_range=[-76, -68], lataxis_range=[-55.8, -40.5], \n",
    "                bgcolor = \"#f9f9f9\", showland = False, showcoastlines = False, showlakes = False)\n",
    "\n",
    "for t in range(0,6): # for each scenario \n",
    "    \n",
    "    # total volume\n",
    "    time_series_id    = dataset_mean[dataset_mean.rgi_id == \"total\"][dataset_mean.scenario == scenarios[t]]\n",
    "    time_series_sd_id = dataset_var[dataset_var.rgi_id == \"total\"][dataset_var.scenario == scenarios[t]]    \n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             marker=dict(color=scen_colors[scenarios[t]]), showlegend=True, legendgroup=t), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup='g1'), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup=t), row=1, col=2)\n",
    "    fig.add_annotation(text=\"b) Total\", font = dict(size = 13), x = 1985, y = 1100, showarrow=False, row=1, col=2)\n",
    "    fig.update_yaxes(range = [1000,3000], dtick = 1000, row = 1, col =2)\n",
    "                     \n",
    "    # zone 1\n",
    "    time_series_id    = dataset_mean[dataset_mean.rgi_id.isin(zone1)][dataset_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = dataset_var[dataset_var.rgi_id.isin(zone1)][dataset_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             marker=dict(color=scen_colors[scenarios[t]]), showlegend=False, legendgroup=t), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup='g1'), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup=t), row=2, col=2)\n",
    "    fig.add_annotation(text=\"c) PPY + PCA\", font = dict(size = 13), x = 2000, y = 3, showarrow=False, row=2, col=2)\n",
    "    fig.update_yaxes(range = [0,45], row = 2, col =2)\n",
    "    \n",
    "    # zone 2\n",
    "    time_series_id    = dataset_mean[dataset_mean.rgi_id.isin(zone2)][dataset_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = dataset_var[dataset_var.rgi_id.isin(zone2)][dataset_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             marker=dict(color=scen_colors[scenarios[t]]), showlegend=False, legendgroup=t), row=2, col=3)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup='g1'), row=2, col=3)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup=t), row=2, col=3)\n",
    "    fig.add_annotation(text=\"d) NPI\", font = dict(size = 13), x = 1990, y = 220, showarrow=False, row=2, col=3)\n",
    "    fig.update_yaxes(range = [200,550], row = 2, col = 3)\n",
    "    \n",
    "    # zone 3\n",
    "    time_series_id    = dataset_mean[dataset_mean.rgi_id.isin(zone3)][dataset_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = dataset_var[dataset_var.rgi_id.isin(zone3)][dataset_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             marker=dict(color=scen_colors[scenarios[t]]), showlegend=False, legendgroup=t), row=3, col=2)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup='g1'), row=3, col=2)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup=t), row=3, col=2)\n",
    "    fig.add_annotation(text=\"e) SPI\", font = dict(size = 13), x = 1990, y = 600, showarrow=False, row=3, col=2)\n",
    "    fig.update_yaxes(range = [500,2000], row = 3, col = 2)\n",
    "    \n",
    "    # zone 4\n",
    "    time_series_id    = dataset_mean[dataset_mean.rgi_id.isin(zone4)][dataset_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = dataset_var[dataset_var.rgi_id.isin(zone4)][dataset_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=time_series_id.melt_on_glacier, mode='lines', name= scenarios[t], \n",
    "                             marker=dict(color=scen_colors[scenarios[t]]), showlegend=False, legendgroup=t), row=3, col=3)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier+time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup='g1'), row=3, col=3)\n",
    "    fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=(time_series_id.melt_on_glacier-time_series_sd_id.melt_on_glacier), \n",
    "                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup=t), row=3, col=3)\n",
    "    fig.add_annotation(text=\"f) GCN + CDI\", font = dict(size = 13), x = 2000, y = 60, showarrow=False, row=3, col=3)\n",
    "    fig.update_yaxes(range = [50,200], row = 3, col = 3)\n",
    "    \n",
    "fig.update_layout(plot_bgcolor=\"rgba(213,213,213,0.6)\")\n",
    "fig.update_xaxes(griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", zeroline=False, showline = True, linecolor = 'black', linewidth = 1, ticks=\"outside\", mirror=True)\n",
    "fig.update_yaxes(griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", zeroline=True,  showline = True, linecolor = 'black', linewidth = 1, ticks=\"outside\", mirror=True)    \n",
    "    \n",
    "fig.update_yaxes(tickangle = -90)\n",
    "fig.update_xaxes(dtick = 20)\n",
    "fig.update_layout(legend=dict(yanchor=\"top\", y=1.0, orientation = \"h\", xanchor=\"left\", x=0.35, bgcolor = 'rgba(0,0,0,0.0)'))\n",
    "fig.update_layout(width = 1000, height = 600, margin = dict(l=20, r=20, b=20, t=20), hovermode = False)\n",
    "\n",
    "fig.write_image(\"/home/rooda/Dropbox/Patagonia/MS2 Results/Figure_9_hydro_projection.png\", scale=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6ee36-bde4-47a3-ac27-ab0214701347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
