{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546609a9-0940-419c-ae28-cac52ea2ec11",
   "metadata": {},
   "source": [
    "# Figure 8: Glacier projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from   plotly.subplots import make_subplots\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3ecdb-8e00-4ce7-a335-456be04f2221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocessing(ds, scenario): # clean dataframe\n",
    "    ds = ds.to_dataframe()\n",
    "    ds[\"scenario\"] = scenario\n",
    "    ds = ds.set_index(\"scenario\", append=True)\n",
    "    ds = ds.reorder_levels(['scenario', 'rgi_id', 'time'])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8ce5-9cae-42de-8be3-873b622cdc37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df765bda-8d26-44c6-9088-ffe8084bfc88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d969c-e4a2-444c-89be-0e2c47928497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins = gpd.read_file(\"zip:////home/rooda/Dropbox/Patagonia/MS2 Results/zenodo/basins_boundaries.zip\")\n",
    "basins = basins[[\"basin_id\", \"basin_zone\", \"basin_name\", \"geometry\"]].set_index(\"basin_id\")\n",
    "basins['basin_name']= basins['basin_name'].replace({'Santa Cruz': 'Santa Cruz                          '})\n",
    "area = pd.read_csv(\"/home/rooda/Dropbox/Patagonia/MS2 Results/zenodo/dataset_historical.csv\", index_col = \"basin_id\").area_RGI6\n",
    "vol  = pd.read_csv(\"/home/rooda/Dropbox/Patagonia/MS2 Results/zenodo/dataset_historical.csv\", index_col = \"basin_id\").vol_F19\n",
    "basins = pd.concat([basins, area, vol], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c7897-06d8-4eaf-bd11-c0ecf8c20eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# historical\n",
    "ts_hist = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_historical.nc\")[[\"volume\"]]\n",
    "ids     = basins[basins.index.isin(ts_hist.rgi_id.to_pandas().tolist())]\n",
    "ts_hist = ts_hist.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "ts_hist = ts_hist.groupby('rgi_id').sum() \n",
    "ts_hist_t = ts_hist.sum(dim = \"rgi_id\").assign_coords({\"rgi_id\": \"total\"}).expand_dims('rgi_id')\n",
    "ts_hist   = xr.concat([ts_hist, ts_hist_t], dim = \"rgi_id\")\n",
    "\n",
    "ts_hist_var  = postprocessing(ts_hist.std(dim=\"options\"),  \"historical\")\n",
    "ts_hist_mean = postprocessing(ts_hist.mean(dim=\"options\"), \"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e163d-c644-4143-92e6-997ca1c7f166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# future\n",
    "os.chdir('/home/rooda/OGGM_results/')\n",
    "scenarios        = [\"ct_random\", \"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"]\n",
    "\n",
    "ts_future_mean = []\n",
    "ts_future_var  = []\n",
    "\n",
    "for scenario in tqdm(scenarios): \n",
    "    ts_future_ssp   = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_future_{}.nc\".format(scenario))[[\"volume\"]]\n",
    "    ids             = basins[basins.index.isin(ts_future_ssp.rgi_id.to_pandas().tolist())]\n",
    "    ts_future_ssp   = ts_future_ssp.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "    ts_future_ssp   = ts_future_ssp.groupby('rgi_id').sum()\n",
    "    ts_future_ssp_t = ts_future_ssp.sum(dim = \"rgi_id\").assign_coords({\"rgi_id\": \"total\"}).expand_dims('rgi_id')\n",
    "    ts_future_ssp   = xr.concat([ts_future_ssp, ts_future_ssp_t], dim = \"rgi_id\")\n",
    "    \n",
    "    ts_future_mean.append(postprocessing(ts_future_ssp.mean(dim=\"options\"), scenario))\n",
    "    ts_future_var.append(postprocessing(ts_future_ssp.std(dim=\"options\"),   scenario))\n",
    "\n",
    "ts_future_var  = pd.concat(ts_future_var)\n",
    "ts_future_mean = pd.concat(ts_future_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c22763-3843-43fc-99b2-d7d61c114e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concat historical and future perios\n",
    "ts_var  = pd.concat([ts_hist_var,  ts_future_var]).reset_index()\n",
    "ts_mean = pd.concat([ts_hist_mean, ts_future_mean]).reset_index()\n",
    "\n",
    "dict_replace = {\"scenario\": {\"historical\":'Historical', \n",
    "                             \"ct_random\":'Commitment run', \n",
    "                             \"ssp126\":'SSP 1-2.6', \n",
    "                             \"ssp245\":'SSP 2-4.5',\n",
    "                             \"ssp370\":'SSP 3-7.0', \n",
    "                             \"ssp585\":'SSP 5-8.5'}}\n",
    "\n",
    "ts_var      = ts_var.replace(dict_replace)\n",
    "ts_mean     = ts_mean.replace(dict_replace)\n",
    "ts_mean_ref = ts_mean[(ts_mean.time == 2020) & (ts_mean.scenario == \"Historical\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ce624-2131-4ab7-82d2-ab63f929859b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Volume loss for each catchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5172961-c55b-4c4a-a182-1c5cc4a125b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "volume_loss = xr.open_mfdataset(\"/home/rooda/OGGM_results/runs/OGGM_future_ssp*.nc\").volume\n",
    "volume_loss = volume_loss / volume_loss.sel(time = 2020)\n",
    "volume_loss = volume_loss.sel(time = 2099)\n",
    "\n",
    "basins  = pd.concat([basins, volume_loss.mean(dim = \"options\").to_dataframe().volume.rename(\"volume_mean\")], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce346e3-da56-499b-ab2a-43d0a873f285",
   "metadata": {},
   "source": [
    "## Plot elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efc0d8-63a1-42fa-8df4-686fe8c78727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basemap for background\n",
    "geo_map = gpd.read_file(\"/home/rooda/Dropbox/ArcGIS/Chile/south_america.shp\")\n",
    "geo_map = geo_map[(geo_map.CC == \"CI\") | (geo_map.CC == \"AR\")]\n",
    "geo_map = geo_map.dissolve(by='REGION')\n",
    "geo_map[\"geometry\"] = geo_map.simplify(0.01)\n",
    "\n",
    "poly_gdf = shapely.geometry.Polygon([(-76, -55.7), (-76, -40.52), (-68.05, -40.52), (-68.05, -55.7), (-76, -55.8)])\n",
    "poly_gdf = gpd.GeoDataFrame([1], geometry=[poly_gdf], crs=geo_map.crs)\n",
    "\n",
    "geo_map = geo_map.clip(poly_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe7259-0815-4e84-b4cc-19abbdb788b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydrological zone divides\n",
    "geo_lines = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Basins_Patagonia_ice_divides.shp\")\n",
    "\n",
    "lats = []\n",
    "lons = []\n",
    "\n",
    "for feature in geo_lines.geometry:\n",
    "    if isinstance(feature, shapely.geometry.linestring.LineString):\n",
    "        linestrings = [feature]\n",
    "    elif isinstance(feature, shapely.geometry.multilinestring.MultiLineString):\n",
    "        linestrings = feature.geoms\n",
    "    else:\n",
    "        continue\n",
    "    for linestring in linestrings:\n",
    "        x, y = linestring.xy\n",
    "        lats = np.append(lats, y)\n",
    "        lons = np.append(lons, x)\n",
    "        lats = np.append(lats, None)\n",
    "        lons = np.append(lons, None)\n",
    "        \n",
    "lat_coords = [-43.2, -45.95,  -46.4,  -47.55,  -49.2,   -50.5,   -52.0, -53.1, -54.8]\n",
    "lon_coords = [-71.2, -71.7,   -74.5,  -71.7,   -72.2,   -72.3,   -72.1, -71.7, -68.9]\n",
    "names      = [\"PPY\", \"PCA\", \"NPI-W\", \"NPI-E\", \"SPI-N\", \"SPI-C\", \"SPI-S\", \"GCN\", \"CDI\"]\n",
    "names  = ['<b>'+x+'</b>' for x in names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03cdee-b798-4dc9-8245-6acd9b8a13c0",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81749ae5-4ef1-4b88-b232-44b25296fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = px.colors.colorbrewer.RdYlBu\n",
    "\n",
    "scenarios   = [\"Historical\", \"Commitment run\", \"SSP 1-2.6\", \"SSP 2-4.5\", \"SSP 3-7.0\", \"SSP 5-8.5\"]\n",
    "scen_colors = {\"Historical\":\"rgba(0, 0, 0, 0.8)\", \n",
    "               \"Commitment run\":\"rgba(0, 0, 0, 0.5)\", \n",
    "               \"SSP 1-2.6\":cl[9], \n",
    "               \"SSP 2-4.5\":cl[8], \n",
    "               \"SSP 3-7.0\":cl[3],\n",
    "               \"SSP 5-8.5\":cl[1]}\n",
    "\n",
    "shaded_colors = {\"Historical\":\"rgba(0, 0, 0, 0.1)\", \n",
    "                 \"SSP 1-2.6\": \"rgba(49,54,149, 0.1)\", \n",
    "                 \"SSP 5-8.5\": \"rgba(215,48,39,0.1)\"}\n",
    "\n",
    "zone1  = ['PPY', 'PCA']\n",
    "zone2  = ['NPI-E','NPI-W']\n",
    "zone3  = ['SPI-N', 'SPI-C', 'SPI-S']\n",
    "zone4  = ['GCN', 'CDI']\n",
    "\n",
    "fig    = make_subplots(rows=3, cols=3, horizontal_spacing = 0.04, vertical_spacing = 0.05, \n",
    "                       shared_xaxes= True, shared_yaxes= True, subplot_titles = [\"Ensemble volume loss in 2100\", \"Volume loss (relative to 2020)\"],\n",
    "                       specs=[[{\"type\": \"scattergeo\", \"rowspan\": 3},  {\"type\": \"xy\", \"colspan\": 2},           None],\n",
    "                              [ None,                         {\"type\": \"xy\"},               {\"type\": \"xy\"}],\n",
    "                              [ None,                         {\"type\": \"xy\"},               {\"type\": \"xy\"}]])\n",
    "\n",
    "fig.add_trace(go.Choropleth(geojson = eval(geo_map['geometry'].to_json()),  locations = geo_map.index, z = geo_map['iso_num'], \n",
    "                            colorscale = [\"#EAEAF2\", \"#EAEAF2\"], showscale= False, marker_line_color ='white', marker_line_width=0.1), row=1, col=1)\n",
    "\n",
    "\n",
    "colorbar_volume = dict(len=0.45, x=0.2, y= 0.77, title='Volume loss<br> (rel. to 2020)', ticksuffix = \" %\", thickness=20, tickwidth=1, title_font =  dict(size = 12))\n",
    "fig.add_trace(go.Choropleth(geojson = eval(basins['geometry'].to_json()),  locations = basins.index, z = (basins['volume_mean']*100)-100, \n",
    "                            colorscale = [(0., cl[2]),(0.4, \"#ffe9ba\"),(1, cl[9])], marker_line_color ='white', marker_line_width=0.1, \n",
    "                            zmin = -100, zmax = -20, colorbar = colorbar_volume), row=1, col=1)\n",
    "fig.add_annotation(text=\"(a)\", font=dict(size=16), x=0.005, y=0.995,  xref = \"paper\", yref = \"paper\", showarrow=False)\n",
    "\n",
    "## Add basin and hydrological zone names plus the hydro zone divides\n",
    "fig.add_trace(go.Scattergeo(lon = lons, lat = lats, mode = 'lines', line = dict(width = 0.8, color = 'black'), opacity = 0.7, showlegend = False),row=1, col=1)  \n",
    "fig.add_trace(go.Scattergeo(lon = lon_coords, lat=lat_coords, mode='text', text=names, textfont=dict(size=12, color = \"rgba(0,0,0,0.7)\"), showlegend = False),row=1, col=1)\n",
    "fig.add_scattergeo(geojson = eval(basins['geometry'].to_json()), locations = basins.index, text = basins['basin_name'], mode = 'text', showlegend = False,\n",
    "                   textfont=dict(size=11, color = \"rgba(0,0,0,0.3)\"),row=1, col=1)\n",
    "\n",
    "fig.update_geos(showframe = True, framewidth = 1,  framecolor = \"black\", lonaxis_range=[-76, -68], lataxis_range=[-55.8, -40.5], \n",
    "                bgcolor = \"rgb(255,255,255)\", showland = False, showcoastlines = False, showlakes = False)\n",
    "\n",
    "for t in range(0,6): # for each scenario \n",
    "    \n",
    "    # total volume\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id == \"total\"][ts_mean.scenario == scenarios[t]]\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id == \"total\"][ts_var.scenario == scenarios[t]]    \n",
    "    ts_ref_id         = ts_mean_ref[ts_mean_ref.rgi_id == \"total\"]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.time, y=(time_series_id.volume/float(ts_ref_id.volume))-1, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=True), row=1, col=2)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=((time_series_id.volume+time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=1, col=2)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=((time_series_id.volume-time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=1, col=2)\n",
    "    fig.add_annotation(text=\"(b) Total\", font = dict(size = 13), x = 1985, y = -0.92, showarrow=False, row=1, col=2)\n",
    "    \n",
    "    # zone 1\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id.isin(zone1)][ts_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id.isin(zone1)][ts_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    ts_ref_id         = ts_mean_ref[ts_mean_ref.rgi_id.isin(zone1)].groupby(\"time\").sum()\n",
    "    \n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=(time_series_id.volume/float(ts_ref_id.volume))-1, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=2, col=2)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=((time_series_id.volume+time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=2, col=2)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=((time_series_id.volume-time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=2, col=2)\n",
    "    fig.add_annotation(text=\"(c) PPY + PCA\", font = dict(size = 13), x = 2000, y = -0.92, showarrow=False, row=2, col=2)\n",
    "    \n",
    "    # zone 2\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id.isin(zone2)][ts_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id.isin(zone2)][ts_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    ts_ref_id         = ts_mean_ref[ts_mean_ref.rgi_id.isin(zone2)].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=(time_series_id.volume/float(ts_ref_id.volume))-1, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=2, col=3)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=((time_series_id.volume+time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=2, col=3)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=((time_series_id.volume-time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=2, col=3)\n",
    "    fig.add_annotation(text=\"(d) NPI\", font = dict(size = 13), x = 1990, y = -0.92, showarrow=False, row=2, col=3)\n",
    "    \n",
    "    # zone 3\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id.isin(zone3)][ts_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id.isin(zone3)][ts_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    ts_ref_id         = ts_mean_ref[ts_mean_ref.rgi_id.isin(zone3)].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=(time_series_id.volume/float(ts_ref_id.volume))-1, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=3, col=2)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=((time_series_id.volume+time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=3, col=2)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=((time_series_id.volume-time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=3, col=2)\n",
    "    fig.add_annotation(text=\"(e) SPI\", font = dict(size = 13), x = 1990, y = -0.92, showarrow=False, row=3, col=2)\n",
    "\n",
    "    # zone 4\n",
    "    time_series_id    = ts_mean[ts_mean.rgi_id.isin(zone4)][ts_mean.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    time_series_sd_id = ts_var[ts_var.rgi_id.isin(zone4)][ts_var.scenario == scenarios[t]].groupby(\"time\").sum()\n",
    "    ts_ref_id         = ts_mean_ref[ts_mean_ref.rgi_id.isin(zone4)].groupby(\"time\").sum()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=time_series_id.index, y=(time_series_id.volume/float(ts_ref_id.volume))-1, mode='lines', name= scenarios[t], \n",
    "                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=3, col=3)\n",
    "    if t == 0 or t == 2 or t >= 5:\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=((time_series_id.volume+time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=3, col=3)\n",
    "        fig.add_trace(go.Scatter(x=time_series_sd_id.index, y=((time_series_id.volume-time_series_sd_id.volume)/float(ts_ref_id.volume))-1, \n",
    "                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=3, col=3)\n",
    "    fig.add_annotation(text=\"(f) GCN + CDI\", font = dict(size = 13), x = 1999, y = -0.92, showarrow=False, row=3, col=3)\n",
    "\n",
    "fig.update_xaxes(griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", zeroline=False, showline = True, linecolor = 'black', linewidth = 1, ticks=\"outside\", mirror=True)\n",
    "fig.update_yaxes(griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", zeroline=False,  showline = True, linecolor = 'black', linewidth = 1, ticks=\"outside\", mirror=True)    \n",
    "    \n",
    "fig.update_yaxes(tickformat = ',.0%', tickangle = -90, range = [-1, 0.19], dtick = 0.3)\n",
    "fig.update_xaxes(dtick = 20)\n",
    "fig.update_layout(legend=dict(yanchor=\"top\", y=0.97, orientation = \"h\", xanchor=\"left\", x=0.35, bgcolor = 'rgba(0,0,0,0.0)'))\n",
    "fig.update_layout(width = 1000, height = 600, template = \"seaborn\", margin = dict(l=20, r=20, b=20, t=20), hovermode = False)\n",
    "\n",
    "fig.write_image(\"/home/rooda/Dropbox/Patagonia/MS2 Results/Figure_8_Glacier_projection.png\", scale=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52e14c-3705-4213-a558-f80e9117fc0f",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29cb51a-17bc-477b-af54-446472808a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss more than 50% of its volume\n",
    "volume_loss = xr.open_mfdataset(\"/home/rooda/OGGM_results/runs/OGGM_future_ssp*.nc\").volume\n",
    "volume_loss = volume_loss / volume_loss.sel(time = 2020)\n",
    "volume_loss = volume_loss.sel(time = 2099)\n",
    "\n",
    "renames = [y + \"_\" + str(x) for x, y in zip(np.tile(np.arange(1,481), 4),  volume_loss.options.values)]\n",
    "volume_loss = volume_loss.assign_coords(options = renames)\n",
    "volume_loss = volume_loss.to_dataframe()[[\"volume\"]].reset_index()\n",
    "volume_loss = volume_loss.pivot(index = \"rgi_id\", columns='options', values='volume')\n",
    "volume_loss = pd.concat([basins, volume_loss], axis=1)\n",
    "\n",
    "loss = []\n",
    "\n",
    "for scenario in range(4, 1924):\n",
    "    value = volume_loss[(volume_loss.iloc[:,scenario]*100)-100 < -50].area_RGI6.sum()*100 / basins.area_RGI6.sum()\n",
    "    loss.append(value)\n",
    "\n",
    "\"Considering  the full set of SSP scenarios (n = 1920), {:.0f}% + {:.0f}% of the total glacier area will lose more than 50% of their current volume\".format(\n",
    "np.mean(loss),  np.std(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103de04c-f207-4abc-973f-3460a101fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# committed loss\n",
    "volume_loss = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_future_ct_random.nc\").volume\n",
    "volume_loss = volume_loss.sum(dim = \"rgi_id\")\n",
    "volume_loss = 1 - (volume_loss / volume_loss.sel(time = 2020))\n",
    "volume_loss = volume_loss.sel(time = 2099) * 100\n",
    "\n",
    "\"{:.0f}% ± {:.0f}% of the total glacier ice is committed to melt in the long term\".format(\n",
    "    float(volume_loss.mean()), float(volume_loss.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb4944-743e-4206-956f-af26c2be5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by scenario \n",
    "volume_loss = xr.open_mfdataset(\"/home/rooda/OGGM_results/runs/OGGM_future_ssp*.nc\").volume\n",
    "volume_loss = volume_loss.sum(dim = \"rgi_id\")\n",
    "volume_loss = 1 - (volume_loss / volume_loss.sel(time = 2020))\n",
    "volume_loss = volume_loss.sel(time = 2099) * 100\n",
    "\n",
    "\"Aggregating the time series by emission scenario (n = 480 per SSP), the volume loss varied from {:.0f} ± {:.0f}% in SSP1-2.6 to {:.0f} ± {:.0f}% in SSP5-8.5\".format(\n",
    "    float(volume_loss.sel(options = \"ssp126\").mean()),\n",
    "    float(volume_loss.sel(options = \"ssp126\").std()),\n",
    "    float(volume_loss.sel(options = \"ssp585\").mean()),\n",
    "    float(volume_loss.sel(options = \"ssp585\").std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d635260-ed4a-45d5-af18-0ccb7f832ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # by scenario and hydro zone\n",
    "volume_loss = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_future_ssp585.nc\").volume\n",
    "volume_loss = volume_loss.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "volume_loss = volume_loss.groupby('rgi_id').sum()\n",
    "\n",
    "volume_loss_npi = volume_loss.sel(rgi_id = volume_loss.rgi_id.isin([\"NPI-E\", \"NPI-W\"])).sum(dim = \"rgi_id\")\n",
    "volume_loss_npi = 1 - (volume_loss_npi / volume_loss_npi.sel(time = 2020))\n",
    "volume_loss_npi = volume_loss_npi.sel(time = 2099) * 100\n",
    "\n",
    "volume_loss_spi = volume_loss.sel(rgi_id = volume_loss.rgi_id.isin([\"SPI-N\", \"SPI-C\", \"SPI-S\"])).sum(dim = \"rgi_id\")\n",
    "volume_loss_spi = 1 - (volume_loss_spi / volume_loss_spi.sel(time = 2020))\n",
    "volume_loss_spi = volume_loss_spi.sel(time = 2099) * 100\n",
    "\n",
    "volume_loss_cdi = volume_loss.sel(rgi_id = volume_loss.rgi_id.isin([\"CDI\", \"GCN\"])).sum(dim = \"rgi_id\")\n",
    "volume_loss_cdi = 1 - (volume_loss_cdi / volume_loss_cdi.sel(time = 2020))\n",
    "volume_loss_cdi = volume_loss_cdi.sel(time = 2099) * 100\n",
    "\n",
    "\"In NPI, SPI and the southern area (GCN and CDI), the percentage loss under SSP 5-8.5 will be {:.0f}% ± {:.0f}%, {:.0f}% ± {:.0f}% and {:.0f}% ± {:.0f}%, respectively\".format(\n",
    "    volume_loss_npi.mean(), volume_loss_npi.std(),\n",
    "    volume_loss_spi.mean(), volume_loss_spi.std(),\n",
    "    volume_loss_cdi.mean(), volume_loss_cdi.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeac7a7-ab45-4fdf-8cc4-7b43d7d8aa91",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b35b3-ae8e-4c57-a7bc-d90333101eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(y = basins.geometry.centroid.y, x = (basins['volume_mean']*100)-100, \n",
    "           width = 800, height = 800, size = np.sqrt(basins.vol_F19)*2, range_x = [-100,0], \n",
    "           labels={\"x\": \"Volume loss in 2100 (rel. to 2020)\",\n",
    "                     \"y\": \"Latitude (ºS)\"  })\n",
    "fig.update_layout(font_size = 16)\n",
    "fig.write_image(\"/home/rooda/Dropbox/Patagonia/MS2 Results/Figure_8_Glacier_projection_review.png\", scale=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
