{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546609a9-0940-419c-ae28-cac52ea2ec11",
   "metadata": {},
   "source": [
    "# Partioning the evolution of uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from oggm import utils\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from   plotly.subplots import make_subplots\n",
    "\n",
    "cl     = px.colors.qualitative.D3\n",
    "os.chdir('/home/rooda/OGGM_results/')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8ce5-9cae-42de-8be3-873b622cdc37",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ids for each glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736e790-88d1-41ba-968d-868a03abde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGI6_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI7_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI7_v2.shp\")\n",
    "RGI6_ids = RGI6_ids[RGI6_ids.area_km2 > 7][[\"RGIId\", \"Zone\"]]\n",
    "RGI7_ids = RGI7_ids[RGI7_ids.area_km2 > 7]\n",
    "\n",
    "# RGI6 doesnt have IDs yet \n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'Zone' : 'Zone'})\n",
    "\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"Zone\"]]\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")\n",
    "\n",
    "dict_zone = {1:'PPY', 2:'PCA', 3:'NPI-E', 4:'NPI-W', 5:'SPI-N', 6:'SPI-C', 7:'SPI-S', 8:'GCN', 9:'CDI'}\n",
    "ids = ids.replace({\"Zone\": dict_zone})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eda580-9ab5-4832-8a0e-27a9efbf7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds): # remove unnecessary variables and coordinates\n",
    "    return ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])[variables]\n",
    "\n",
    "def hydro_variables(ds): # calculate total_runoff, melt_on_glacier and smb\n",
    "    ds[\"total_runoff\"] = ((ds.melt_off_glacier + ds.melt_on_glacier + ds.liq_prcp_off_glacier + ds.liq_prcp_on_glacier)*1e-3)/(365*86400) # m3/s\n",
    "    ds[\"melt_on_glacier\"] = ((ds.melt_on_glacier)*1e-3)/(365*86400) # m3\n",
    "    ds[\"smb\"] = (ds.volume.diff(dim = \"time\") * 900 / ds.area) \n",
    "    return ds[variables_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13c635-6db5-4978-b3aa-0705748f7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to analize\n",
    "variables        = ['melt_off_glacier', 'melt_on_glacier', 'liq_prcp_off_glacier', 'liq_prcp_on_glacier', 'volume', 'area']\n",
    "variables_final  = ['total_runoff','melt_on_glacier', 'smb']\n",
    "scenarios        = [\"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e84543-321c-47e3-9f6c-64cb08310223",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mean = []\n",
    "dataset_var  = []\n",
    "\n",
    "for scenario in tqdm(scenarios): \n",
    "    all_combs = glob(\"/home/rooda/OGGM_results/new/*/run_output_*\"+ scenario +\"*.nc\", recursive = True)\n",
    "    all_opts   = xr.open_mfdataset(all_combs, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "    # assing zone to each glacier and aggregate the result \n",
    "    ids_subset = ids[ids.index.isin(all_opts.rgi_id.to_pandas().tolist())]\n",
    "    all_opts   = all_opts.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "    all_opts   = all_opts.groupby('rgi_id').sum()\n",
    "    all_opts   = all_opts.chunk(\"auto\")\n",
    "    all_opts   = hydro_variables(all_opts)\n",
    "    all_opts   = all_opts.isel(time = slice(0, -1))\n",
    "    \n",
    "    # standard desviation\n",
    "    all_opts_var = all_opts.std(dim=\"options\")\n",
    "    all_opts_var = all_opts_var.to_dataframe()\n",
    "    all_opts_var[\"scenario\"] = scenario\n",
    "    all_opts_var = all_opts_var.set_index(\"scenario\", append=True)\n",
    "    all_opts_var = all_opts_var.reorder_levels(['scenario', 'rgi_id', 'time'])\n",
    "    dataset_var.append(all_opts_var)\n",
    "    \n",
    "    # mean\n",
    "    all_opts_mean = all_opts.mean(dim=\"options\")\n",
    "    all_opts_mean = all_opts_mean.to_dataframe()\n",
    "    all_opts_mean[\"scenario\"] = scenario\n",
    "    all_opts_mean = all_opts_mean.set_index(\"scenario\", append=True)\n",
    "    all_opts_mean = all_opts_mean.reorder_levels(['scenario', 'rgi_id', 'time'])\n",
    "    dataset_mean.append(all_opts_mean)\n",
    "    \n",
    "dataset_mean = pd.concat(dataset_mean)\n",
    "dataset_var  = pd.concat(dataset_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e0bc3-3491-4e43-ba3d-0257fcb0cee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variable = \"total_runoff\"\n",
    "dict_names ={\"melt_on_glacier\": \"Melt on glacier (m<sup>3</sup> s<sup>-1</sup>)\", \n",
    "             \"total_runoff\"   : \"Total runoff (m<sup>3</sup> s<sup>-1</sup>)\", \n",
    "             \"smb\"            : \"Specific mass balance (kg m<sup>-2</sup>)\"}\n",
    "\n",
    "scenarios  = [\"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"]\n",
    "dict_colors = {\"ssp126\":cl[0], \"ssp245\":cl[2], \"ssp370\":cl[1], \"ssp585\":cl[3]}\n",
    "\n",
    "basins_id  = np.array(['PPY', 'PCA','NPI-E','NPI-W','SPI-N', 'SPI-C', 'SPI-S', 'GCN', 'CDI']).reshape(3,3)\n",
    "fig    = make_subplots(rows=3, cols=3, horizontal_spacing = 0.05, vertical_spacing = 0.035, shared_xaxes= True, shared_yaxes= False, \n",
    "                       subplot_titles=basins_id.reshape(1,9)[0], y_title = dict_names[variable])\n",
    "\n",
    "time_series = dataset_mean.reset_index()\n",
    "time_series_sd = dataset_var.reset_index()\n",
    "\n",
    "\n",
    "for x in range(0,3):\n",
    "    for y in range(0,3):\n",
    "        for t in range(0,4):\n",
    "        \n",
    "            # legend only for first plot\n",
    "            if x==0 and y==0:\n",
    "                # time series\n",
    "                time_series_id = time_series[time_series.rgi_id == basins_id[x,y]][time_series.scenario == scenarios[t]]\n",
    "                time_series_sd_id = time_series_sd[time_series_sd.rgi_id == basins_id[x,y]][time_series_sd.scenario == scenarios[t]]\n",
    "        \n",
    "                fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id[variable], mode='lines', name= scenarios[t], \n",
    "                                     marker=dict(color=dict_colors[scenarios[t]]), showlegend=True, legendgroup='g1'), row=x+1, col=y+1)\n",
    "            # time series\n",
    "            time_series_id = time_series[time_series.rgi_id == basins_id[x,y]][time_series.scenario == scenarios[t]]\n",
    "            time_series_sd_id = time_series_sd[time_series_sd.rgi_id == basins_id[x,y]][time_series_sd.scenario == scenarios[t]]\n",
    "\n",
    "            # mean value\n",
    "            fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id[variable], mode='lines', name= scenarios[t], \n",
    "                                     marker=dict(color=dict_colors[scenarios[t]]), showlegend=False, legendgroup='g1'), row=x+1, col=y+1)\n",
    "            \n",
    "            # uncertainty: +-1 sd\n",
    "            fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=time_series_id[variable]+time_series_sd_id[variable], line=dict(width=0),\n",
    "                             fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup='g1'), row=x+1, col=y+1)\n",
    "            fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=time_series_id[variable]-time_series_sd_id[variable], line=dict(width=0),\n",
    "                             fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup='g1'), row=x+1, col=y+1)\n",
    "\n",
    "fig.update_yaxes(ticks=\"outside\")\n",
    "fig.update_layout(legend=dict(yanchor=\"top\", y=0.45, xanchor=\"left\", x=0.35, orientation=\"v\", bgcolor = 'rgba(0,0,0,0.0)'))\n",
    "fig.update_layout(height=800, width=1100, template = \"seaborn\", margin = dict(l=100, r=20, b=20, t=20))\n",
    "fig.write_image(\"/home/rooda/Dropbox/Patagonia/MS2 Results/Figure_ts_\" + variable + \".png\", scale=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7df1b-1020-4408-90d3-72f8bae976a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
