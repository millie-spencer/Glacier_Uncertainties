{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546609a9-0940-419c-ae28-cac52ea2ec11",
   "metadata": {},
   "source": [
    "# Figure S1: Glacier projections by hydrological zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from oggm import utils\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from   plotly.subplots import make_subplots\n",
    "\n",
    "cl     = px.colors.qualitative.D3\n",
    "os.chdir('/home/rooda/OGGM_results/')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8ce5-9cae-42de-8be3-873b622cdc37",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ids for each glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736e790-88d1-41ba-968d-868a03abde15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RGI6_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI7_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI7_v2.shp\")\n",
    "RGI6_ids = RGI6_ids[RGI6_ids.area_km2 > 1][[\"RGIId\", \"Zone\"]]\n",
    "RGI7_ids = RGI7_ids[RGI7_ids.area_km2 > 1]\n",
    "\n",
    "# RGI6 doesnt have IDs yet \n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'Zone' : 'Zone'})\n",
    "\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"Zone\"]]\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")\n",
    "\n",
    "dict_zone = {1:'PPY', 2:'PCA', 3:'NPI-E', 4:'NPI-W', 5:'SPI-N', 6:'SPI-C', 7:'SPI-S', 8:'GCN', 9:'CDI'}\n",
    "ids = ids.replace({\"Zone\": dict_zone})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eda580-9ab5-4832-8a0e-27a9efbf7d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(ds): # remove unnecessary variables and coordinates\n",
    "    return ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])[variables]\n",
    "\n",
    "def postprocessing(ds, scenario): # clean dataframe\n",
    "    ds = ds.to_dataframe()\n",
    "    ds[\"scenario\"] = scenario\n",
    "    ds = ds.set_index(\"scenario\", append=True)\n",
    "    ds = ds.reorder_levels(['scenario', 'rgi_id', 'time'])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13c635-6db5-4978-b3aa-0705748f7919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# variables to analize\n",
    "variables        = ['volume', 'area']\n",
    "scenarios        = [\"ct_random\",\"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a4296-e82f-4631-876f-0a251ebbdb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# historical period\n",
    "all_combs = glob(\"/home/rooda/OGGM_results/new/*/run_outputs_*.nc\", recursive = True)\n",
    "all_opts   = xr.open_mfdataset(all_combs, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "# assing zone to each glacier and aggregate the result \n",
    "ids_subset = ids[ids.index.isin(all_opts.rgi_id.to_pandas().tolist())]\n",
    "all_opts   = all_opts.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "all_opts   = all_opts.groupby('rgi_id').sum()\n",
    "all_opts   = all_opts.chunk(\"auto\")\n",
    "all_opts[\"smb\"] = (all_opts.volume.diff(dim = \"time\") * 900 / all_opts.area) \n",
    "all_opts   = all_opts.isel(time = slice(0, -1))\n",
    "\n",
    "# standard desviation\n",
    "dataset_var_hist = all_opts.std(dim=\"options\")\n",
    "dataset_var_hist = postprocessing(dataset_var_hist, \"historical\")\n",
    "\n",
    "# mean\n",
    "dataset_mean_hist = all_opts.mean(dim=\"options\")\n",
    "dataset_mean_hist = postprocessing(dataset_mean_hist, \"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0e584-0569-401f-a8af-ff5e22de5b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_mean = []\n",
    "dataset_var  = []\n",
    "\n",
    "for scenario in tqdm(scenarios): \n",
    "    all_combs = glob(\"/home/rooda/OGGM_results/new/*/run_output_*\"+ scenario +\"*.nc\", recursive = True)\n",
    "    all_opts   = xr.open_mfdataset(all_combs, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "    if scenario == \"ct_random\":\n",
    "        all_opts[\"time\"] = all_opts[\"time\"] + 2020\n",
    "    \n",
    "    # assing zone to each glacier and aggregate the result \n",
    "    ids_subset = ids[ids.index.isin(all_opts.rgi_id.to_pandas().tolist())]\n",
    "    all_opts   = all_opts.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "    all_opts   = all_opts.groupby('rgi_id').sum()\n",
    "    all_opts   = all_opts.chunk(\"auto\")\n",
    "    all_opts[\"smb\"] = (all_opts.volume.diff(dim = \"time\") * 900 / all_opts.area) \n",
    "    all_opts   = all_opts.isel(time = slice(0, -1))\n",
    "    \n",
    "    # standard desviation\n",
    "    all_opts_var = all_opts.std(dim=\"options\")\n",
    "    all_opts_var = postprocessing(all_opts_var, scenario)\n",
    "    dataset_var.append(all_opts_var)\n",
    "    \n",
    "    # mean\n",
    "    all_opts_mean = all_opts.mean(dim=\"options\")\n",
    "    all_opts_mean = postprocessing(all_opts_mean, scenario)\n",
    "    dataset_mean.append(all_opts_mean)\n",
    "    \n",
    "dataset_mean = pd.concat(dataset_mean)\n",
    "dataset_mean = pd.concat([dataset_mean_hist, dataset_mean]).reset_index()\n",
    "\n",
    "dataset_var  = pd.concat(dataset_var)\n",
    "dataset_var  = pd.concat([dataset_var_hist, dataset_var]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4268714-3442-4422-93d9-1c720287f3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize volume and area \n",
    "dataset_mean_ref = dataset_mean[dataset_mean.time == 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85861fce-3652-492d-b387-fd02adda78fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_replace = {\"scenario\": {\"historical\":'Historical', \"ct_random\":'Commitment run', \"ssp126\":'SSP 126', \"ssp245\":'SSP 245', \"ssp370\":'SSP 370', \"ssp585\":'SSP 585'}}\n",
    "\n",
    "dataset_mean = dataset_mean.replace(dict_replace)\n",
    "dataset_var  = dataset_var.replace(dict_replace)\n",
    "dataset_mean_ref = dataset_mean_ref.replace(dict_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc0f23-dbb7-4576-8883-f149f3aa22bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenarios   = [\"Historical\", \"Commitment run\", \"SSP 126\", \"SSP 245\", \"SSP 370\", \"SSP 585\"]\n",
    "scen_colors = {\"Historical\":\"rgba(0, 0, 0, 0.8)\", \"Commitment run\":\"rgba(0, 0, 0, 0.5)\", \"SSP 126\":cl[0], \"SSP 245\":cl[2], \"SSP 370\":cl[1], \"SSP 585\":cl[3]}\n",
    "\n",
    "basins_id  = ['PPY', 'PCA','NPI-E','NPI-W','SPI-N', 'SPI-C', 'SPI-S', 'GCN', 'CDI']\n",
    "\n",
    "\n",
    "fig    = make_subplots(rows=9, cols=3, horizontal_spacing = 0.05, vertical_spacing = 0.01, \n",
    "                       shared_xaxes= True, shared_yaxes= False, row_titles = basins_id,\n",
    "                       subplot_titles= [\"Glacier volume (%)\", \"Glacier area (%)\", \"Specific mass balance (kg m<sup>-2</sup>)\"])\n",
    "\n",
    "for x in range(0,9):\n",
    "    for y in range(0,3):\n",
    "        for t in range(0,6):\n",
    "             \n",
    "            # time series for each subplot and scenario\n",
    "            time_series_id    = dataset_mean[dataset_mean.rgi_id == basins_id[x]][dataset_mean.scenario == scenarios[t]]\n",
    "            time_series_sd_id = dataset_var[dataset_var.rgi_id == basins_id[x]][dataset_var.scenario == scenarios[t]]    \n",
    "            ts_ref_id         = dataset_mean_ref[dataset_mean_ref.rgi_id == basins_id[x]]\n",
    "            \n",
    "            if x==0 and y==0: # legend only for first plot\n",
    "        \n",
    "                fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.iloc[:,y+3]/ts_ref_id.iloc[0,y+3], \n",
    "                                         mode='lines', name= scenarios[t], \n",
    "                                         marker=dict(color=scen_colors[scenarios[t]]), showlegend=True, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "                fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]+time_series_sd_id.iloc[:,y+3])/ts_ref_id.iloc[0,y+3], \n",
    "                                         line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup='g1'), row=x+1, col=y+1)\n",
    "                fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]-time_series_sd_id.iloc[:,y+3])/ts_ref_id.iloc[0,y+3], \n",
    "                                         line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "                \n",
    "            else:\n",
    "                if y==2: # dont normalize specific mass balance\n",
    "            \n",
    "                    fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.iloc[:,y+3], mode='lines', name= scenarios[t], \n",
    "                                             marker=dict(color=scen_colors[scenarios[t]]), showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "                    # uncertainty: +-1 sd\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]+time_series_sd_id.iloc[:,y+3]), \n",
    "                                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]-time_series_sd_id.iloc[:,y+3]), \n",
    "                                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "       \n",
    "                else:\n",
    "                    # mean value\n",
    "                    fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.iloc[:,y+3]/ts_ref_id.iloc[0,y+3], mode='lines', name= scenarios[t], \n",
    "                                             marker=dict(color=scen_colors[scenarios[t]]), showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "                    # uncertainty: +-1 sd\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]+time_series_sd_id.iloc[:,y+3])/ts_ref_id.iloc[0,y+3], \n",
    "                                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]-time_series_sd_id.iloc[:,y+3])/ts_ref_id.iloc[0,y+3], \n",
    "                                             line=dict(width=0), fillcolor='rgba(0, 0, 0, 0.05)', fill='tonexty', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "#  some tweaks\n",
    "for x in range(0,9):\n",
    "    for y in range(0,3):                \n",
    "        if y==2: fig.update_yaxes(dtick = 2000,  row=x+1, col=y+1)\n",
    "        else: fig.update_yaxes(range = [0, 1.2], dtick = 0.5, tickformat=\".0%\", row=x+1, col=y+1)\n",
    "        \n",
    "fig.update_yaxes(range = [-5500, 500], dtick = 3000, row=5, col=3)\n",
    "\n",
    "fig.update_yaxes(ticks=\"outside\", griddash = \"dot\", showline = True, linecolor = 'black', linewidth = 0.2, mirror=True, tickangle = -90)\n",
    "fig.update_xaxes(ticks=\"outside\", griddash = \"dot\", showline = True, linecolor = 'black', linewidth = 0.2, mirror=True, dtick = 20)\n",
    "fig.update_layout(legend=dict(yanchor=\"top\", y=-0.02, xanchor=\"left\", x=0.15, orientation=\"h\", bgcolor = 'rgba(0,0,0,0.0)'))\n",
    "fig.update_layout(height=1200, width=1000, template = \"seaborn\", margin = dict(l=20, r=20, b=30, t=30), hovermode = False)\n",
    "fig.update_layout(plot_bgcolor = \"rgba(213,213,213,0.6)\")\n",
    "\n",
    "# save figure \n",
    "#fig.write_image(\"/home/rooda/Dropbox/Patagonia/MS2 Results/Figure_S1_Glacier_projections.png\", scale=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd809df-b4ea-4df7-b6a7-f7b97a9ac782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# regional loss\n",
    "dataset_mean[dataset_mean.rgi_id == \"NPI-E\"][dataset_mean.scenario == scenarios[2]].groupby(\"time\").sum().smb.iloc[50:].mean()\n",
    "dataset_mean[dataset_mean.rgi_id == \"NPI-E\"][dataset_mean.scenario == scenarios[2]].groupby(\"time\").sum().smb.iloc[50:].std()\n",
    "\n",
    "dataset_mean[dataset_mean.rgi_id == \"NPI-E\"][dataset_mean.scenario == scenarios[5]].groupby(\"time\").sum().smb.iloc[50:].mean()\n",
    "dataset_mean[dataset_mean.rgi_id == \"NPI-E\"][dataset_mean.scenario == scenarios[5]].groupby(\"time\").sum().smb.iloc[50:].std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
