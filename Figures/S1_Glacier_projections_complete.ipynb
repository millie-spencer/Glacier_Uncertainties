{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546609a9-0940-419c-ae28-cac52ea2ec11",
   "metadata": {},
   "source": [
    "# Figure S1: Glacier projections by hydrological zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "    \n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from   plotly.subplots import make_subplots\n",
    "\n",
    "os.chdir('/home/rooda/OGGM_results/')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eda580-9ab5-4832-8a0e-27a9efbf7d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocessing(ds, scenario): # clean dataframe\n",
    "    ds = ds.to_dataframe()\n",
    "    ds[\"scenario\"] = scenario\n",
    "    ds = ds.set_index(\"scenario\", append=True)\n",
    "    ds = ds.reorder_levels(['scenario', 'rgi_id', 'time'])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8ce5-9cae-42de-8be3-873b622cdc37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732b4e0-8073-4315-a919-75f57192b904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins = gpd.read_file(\"zip:////home/rooda/Dropbox/Patagonia/MS2 Results/zenodo/basins_boundaries.zip\")[[\"basin_id\", \"basin_zone\"]].set_index(\"basin_id\")\n",
    "\n",
    "# historical\n",
    "ts_hist = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_historical.nc\")[[\"volume\", \"area\"]]\n",
    "ids     = basins[basins.index.isin(ts_hist.rgi_id.to_pandas().tolist())]\n",
    "ts_hist = ts_hist.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "ts_hist = ts_hist.groupby('rgi_id').sum()\n",
    "\n",
    "ts_hist[\"smb\"] = (ts_hist.volume.diff(dim = \"time\") * 900 / ts_hist.area) \n",
    "ts_hist_var  = postprocessing(ts_hist.std(dim=\"options\"),  \"historical\")\n",
    "ts_hist_mean = postprocessing(ts_hist.mean(dim=\"options\"), \"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0e584-0569-401f-a8af-ff5e22de5b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# future\n",
    "scenarios        = [\"ct_random\", \"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"]\n",
    "\n",
    "ts_future_mean = []\n",
    "ts_future_var  = []\n",
    "\n",
    "for scenario in tqdm(scenarios): \n",
    "    ts_future_ssp   = xr.open_dataset(\"/home/rooda/OGGM_results/runs/OGGM_future_{}.nc\".format(scenario))[[\"volume\", \"area\"]]\n",
    "    ids             = basins[basins.index.isin(ts_future_ssp.rgi_id.to_pandas().tolist())]\n",
    "    ts_future_ssp   = ts_future_ssp.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "    ts_future_ssp   = ts_future_ssp.groupby('rgi_id').sum()    \n",
    "    ts_future_ssp[\"smb\"] = (ts_future_ssp.volume.diff(dim = \"time\") * 900 / ts_future_ssp.area) \n",
    "    \n",
    "    ts_future_var.append(postprocessing(ts_future_ssp.std(dim=\"options\"),   scenario))\n",
    "    ts_future_mean.append(postprocessing(ts_future_ssp.mean(dim=\"options\"), scenario))\n",
    "\n",
    "ts_future_var  = pd.concat(ts_future_var)\n",
    "ts_future_mean = pd.concat(ts_future_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4268714-3442-4422-93d9-1c720287f3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concat historical and future perios\n",
    "ts_var  = pd.concat([ts_hist_var,  ts_future_var]).reset_index()\n",
    "ts_mean = pd.concat([ts_hist_mean, ts_future_mean]).reset_index()\n",
    "\n",
    "dict_replace = {\"scenario\": {\"historical\":'Historical', \n",
    "                             \"ct_random\":'Commitment run', \n",
    "                             \"ssp126\":'SSP 1-2.6', \n",
    "                             \"ssp245\":'SSP 2-4.5',\n",
    "                             \"ssp370\":'SSP 3-7.0', \n",
    "                             \"ssp585\":'SSP 5-8.5'}}\n",
    "\n",
    "ts_var      = ts_var.replace(dict_replace)\n",
    "ts_mean     = ts_mean.replace(dict_replace)\n",
    "ts_mean_ref = ts_mean[ts_mean.time == 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa36748-feb8-46e0-bbdc-7cb5da54da4a",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc0f23-dbb7-4576-8883-f149f3aa22bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cl = px.colors.colorbrewer.RdYlBu\n",
    "\n",
    "scenarios   = [\"Historical\", \"Commitment run\", \"SSP 1-2.6\", \"SSP 2-4.5\", \"SSP 3-7.0\", \"SSP 5-8.5\"]\n",
    "scen_colors = {\"Historical\":\"rgba(0, 0, 0, 0.8)\", \n",
    "               \"Commitment run\":\"rgba(0, 0, 0, 0.5)\", \n",
    "               \"SSP 1-2.6\":cl[9], \n",
    "               \"SSP 2-4.5\":cl[8], \n",
    "               \"SSP 3-7.0\":cl[3],\n",
    "               \"SSP 5-8.5\":cl[1]}\n",
    "\n",
    "shaded_colors = {\"Historical\":\"rgba(0, 0, 0, 0.1)\", \n",
    "                 \"SSP 1-2.6\": \"rgba(49,54,149, 0.1)\", \n",
    "                 \"SSP 5-8.5\": \"rgba(215,48,39,0.1)\"}\n",
    "\n",
    "basins_id = ['PPY', 'PCA','NPI-E','NPI-W','SPI-N', 'SPI-C', 'SPI-S', 'GCN', 'CDI']\n",
    "\n",
    "fig    = make_subplots(rows=9, cols=3, horizontal_spacing = 0.04, vertical_spacing = 0.01, shared_xaxes= True, shared_yaxes= False, \n",
    "                       row_titles = basins_id, subplot_titles= [\"Glacier volume (%)\", \"Glacier area (%)\", \"Specific mass balance (kg m<sup>-2</sup>)\"])\n",
    "\n",
    "for x in range(0,9):\n",
    "    for y in range(0,3):\n",
    "        for t in range(0,6):\n",
    "             \n",
    "            # time series for each subplot and scenario\n",
    "            time_series_id    = ts_mean[ts_mean.rgi_id == basins_id[x]][ts_mean.scenario == scenarios[t]]\n",
    "            time_series_sd_id = ts_var[ts_var.rgi_id == basins_id[x]][ts_var.scenario == scenarios[t]]    \n",
    "            ts_ref_id         = ts_mean_ref[ts_mean_ref.rgi_id == basins_id[x]]\n",
    "            \n",
    "            if x==0 and y==0: # legend only for first plot\n",
    "        \n",
    "                fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.iloc[:,y+3]/ts_ref_id.iloc[0,y+3], \n",
    "                                         mode='lines', name= scenarios[t], \n",
    "                                         line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=True, legendgroup=t), row=x+1, col=y+1)\n",
    "                \n",
    "                if t == 0 or t == 2 or t >= 5: # uncertainty: +-1 sd\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]+time_series_sd_id.iloc[:,y+3])/ts_ref_id.iloc[0,y+3], \n",
    "                                             line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=x+1, col=y+1)\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]-time_series_sd_id.iloc[:,y+3])/ts_ref_id.iloc[0,y+3], \n",
    "                                             line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "            else:\n",
    "                if y==2: # dont normalize specific mass balance\n",
    "            \n",
    "                    fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.iloc[:,y+3], mode='lines', name= scenarios[t], \n",
    "                                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "                    if t == 0 or t == 2 or t >= 5: # uncertainty: +-1 sd\n",
    "                        fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]+time_series_sd_id.iloc[:,y+3]), \n",
    "                                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "                        fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]-time_series_sd_id.iloc[:,y+3]), \n",
    "                                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "                else:\n",
    "                    # mean value\n",
    "                    fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.iloc[:,y+3]/ts_ref_id.iloc[0,y+3], mode='lines', name= scenarios[t], \n",
    "                                             line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "                    \n",
    "                    if t == 0 or t == 2 or t >= 5: # uncertainty: +-1 sd\n",
    "                        fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]+time_series_sd_id.iloc[:,y+3])/ts_ref_id.iloc[0,y+3], \n",
    "                                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "                        fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]-time_series_sd_id.iloc[:,y+3])/ts_ref_id.iloc[0,y+3], \n",
    "                                                 line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "#  some tweaks\n",
    "for x in range(0,9):\n",
    "    for y in range(0,3):                \n",
    "        if y==2: fig.update_yaxes(dtick = 2000,  row=x+1, col=y+1)\n",
    "        else: fig.update_yaxes(range = [0, 1.2], dtick = 0.5, tickformat=\".0%\", row=x+1, col=y+1)\n",
    "        \n",
    "fig.update_yaxes(range = [-5500, 500], dtick = 3000, row=5, col=3)\n",
    "\n",
    "fig.update_yaxes(ticks=\"outside\", zeroline=False, griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", showline = True, linecolor = 'black', linewidth = 0.2, mirror=True, tickangle = -90)\n",
    "fig.update_xaxes(ticks=\"outside\", zeroline=False, griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", showline = True, linecolor = 'black', linewidth = 0.2, mirror=True, dtick = 20)\n",
    "fig.update_layout(legend=dict(yanchor=\"top\", y=-0.02, xanchor=\"left\", x=0.15, orientation=\"h\", bgcolor = 'rgba(0,0,0,0.0)'))\n",
    "fig.update_layout(height=1200, width=1050, template = \"seaborn\", margin = dict(l=20, r=20, b=30, t=30), hovermode = False)\n",
    "\n",
    "# save figure \n",
    "fig.write_image(\"/home/rooda/Dropbox/Patagonia/MS2 Results/Figure_S1_Glacier_projections.png\", scale=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f58712-fab9-4300-be36-e1a48f06954c",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd809df-b4ea-4df7-b6a7-f7b97a9ac782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# regional smb\n",
    "ts_future_ssp   = xr.open_mfdataset(\"/home/rooda/OGGM_results/runs/OGGM_future_ssp*.nc\")[[\"volume\", \"area\"]]\n",
    "ts_future_ssp   = ts_future_ssp.sel(time = slice(2070,2100))\n",
    "ids             = basins[basins.index.isin(ts_future_ssp.rgi_id.to_pandas().tolist())]\n",
    "ts_future_ssp   = ts_future_ssp.assign_coords(rgi_id = ids.basin_zone.tolist())\n",
    "ts_future_ssp   = ts_future_ssp.groupby('rgi_id').sum()    \n",
    "ts_future_ssp[\"smb\"] = (ts_future_ssp.volume.diff(dim = \"time\") * 900 / ts_future_ssp.area) \n",
    "ts_future_ssp   = ts_future_ssp.smb.load()\n",
    "\n",
    "\"the mean specific mass balance in NPI-E ranged from {} ± {} kg m-2 in SSP1-2.6 to {} ± {} kg m-2 in SSP 5-8.5\".format(\n",
    "    int(ts_future_ssp.sel(options = \"ssp126\").sel(rgi_id = \"NPI-E\").mean(dim = \"time\").mean(dim = \"options\")),\n",
    "    int(ts_future_ssp.sel(options = \"ssp126\").sel(rgi_id = \"NPI-E\").mean(dim = \"time\").std(dim = \"options\")),\n",
    "    int(ts_future_ssp.sel(options = \"ssp585\").sel(rgi_id = \"NPI-E\").mean(dim = \"time\").mean(dim = \"options\")),\n",
    "    int(ts_future_ssp.sel(options = \"ssp585\").sel(rgi_id = \"NPI-E\").mean(dim = \"time\").std(dim = \"options\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c70d7-597d-4424-bb93-59ed9691ad98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# is the maximum between the scenarios?\n",
    "pd.concat([ts_future_ssp.sel(options = \"ssp126\").mean(dim = \"time\").mean(dim = \"options\").to_dataframe(),\n",
    "           ts_future_ssp.sel(options = \"ssp585\").mean(dim = \"time\").mean(dim = \"options\").to_dataframe()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc44795-c637-4d03-9c88-92c0159972cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
