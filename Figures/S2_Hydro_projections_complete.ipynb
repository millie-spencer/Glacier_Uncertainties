{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546609a9-0940-419c-ae28-cac52ea2ec11",
   "metadata": {},
   "source": [
    "# Figure S2: Hydro projections by hydrological zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from oggm import utils\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from   plotly.subplots import make_subplots\n",
    "\n",
    "cl     = px.colors.qualitative.D3\n",
    "os.chdir('/home/rooda/OGGM_results/')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8ce5-9cae-42de-8be3-873b622cdc37",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ids for each glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736e790-88d1-41ba-968d-868a03abde15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RGI6_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI7_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI7_v2.shp\")\n",
    "RGI6_ids = RGI6_ids[RGI6_ids.area_km2 > 1][[\"RGIId\", \"Zone\"]]\n",
    "RGI7_ids = RGI7_ids[RGI7_ids.area_km2 > 1]\n",
    "\n",
    "# RGI6 doesnt have IDs yet \n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'Zone' : 'Zone'})\n",
    "\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"Zone\"]]\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")\n",
    "\n",
    "dict_zone = {1:'PPY', 2:'PCA', 3:'NPI-E', 4:'NPI-W', 5:'SPI-N', 6:'SPI-C', 7:'SPI-S', 8:'GCN', 9:'CDI'}\n",
    "ids = ids.replace({\"Zone\": dict_zone})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eda580-9ab5-4832-8a0e-27a9efbf7d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(ds): # remove unnecessary variables and coordinates\n",
    "    return ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])\n",
    "\n",
    "def hydro_variables(ds): # calculate total_runoff, melt_on_glacier and smb\n",
    "    ds[\"total_runoff\"] = ((ds.melt_off_glacier + ds.melt_on_glacier + ds.liq_prcp_off_glacier + ds.liq_prcp_on_glacier)*1e-3)/(365*86400) # m3/s\n",
    "    ds[\"melt_on_glacier\"] = ((ds.melt_on_glacier)*1e-3)/(365*86400) # m3\n",
    "    ds[\"ratio\"] = ds[\"melt_on_glacier\"] / ds[\"total_runoff\"]\n",
    "    return ds[variables]\n",
    "\n",
    "def postprocessing(ds, scenario): # clean dataframe\n",
    "    ds = ds.to_dataframe()\n",
    "    ds[\"scenario\"] = scenario\n",
    "    ds = ds.set_index(\"scenario\", append=True)\n",
    "    ds = ds.reorder_levels(['scenario', 'rgi_id', 'time'])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13c635-6db5-4978-b3aa-0705748f7919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# variables to analize\n",
    "variables        = ['total_runoff', 'melt_on_glacier', 'ratio']\n",
    "scenarios        = [\"ct_random\", \"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a4296-e82f-4631-876f-0a251ebbdb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# historical period\n",
    "all_combs = glob(\"/home/rooda/OGGM_results/new/*/run_outputs_*.nc\", recursive = True)\n",
    "all_opts   = xr.open_mfdataset(all_combs, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "# assing zone to each glacier and aggregate the result \n",
    "ids_subset = ids[ids.index.isin(all_opts.rgi_id.to_pandas().tolist())]\n",
    "all_opts   = all_opts.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "all_opts   = all_opts.groupby('rgi_id').sum()\n",
    "all_opts   = all_opts.chunk(\"auto\")\n",
    "all_opts   = hydro_variables(all_opts)\n",
    "all_opts   = all_opts.isel(time = slice(0, -1))\n",
    "\n",
    "# standard desviation\n",
    "dataset_var_hist = all_opts.std(dim=\"options\")\n",
    "dataset_var_hist = postprocessing(dataset_var_hist, \"historical\")\n",
    "\n",
    "# mean\n",
    "dataset_mean_hist = all_opts.mean(dim=\"options\")\n",
    "dataset_mean_hist = postprocessing(dataset_mean_hist, \"historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0e584-0569-401f-a8af-ff5e22de5b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_mean = []\n",
    "dataset_var  = []\n",
    "\n",
    "for scenario in tqdm(scenarios): \n",
    "    all_combs = glob(\"/home/rooda/OGGM_results/new/*/run_output_*\"+ scenario +\"*.nc\", recursive = True)\n",
    "    all_opts   = xr.open_mfdataset(all_combs, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "    if scenario == \"ct_random\":\n",
    "        all_opts[\"time\"] = all_opts[\"time\"] + 2020\n",
    "    \n",
    "    # assing zone to each glacier and aggregate the result \n",
    "    ids_subset = ids[ids.index.isin(all_opts.rgi_id.to_pandas().tolist())]\n",
    "    all_opts   = all_opts.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "    all_opts   = all_opts.groupby('rgi_id').sum()\n",
    "    all_opts   = all_opts.chunk(\"auto\")\n",
    "    all_opts   = hydro_variables(all_opts)\n",
    "    all_opts   = all_opts.isel(time = slice(0, -1))\n",
    "    \n",
    "    # standard desviation\n",
    "    all_opts_var = all_opts.std(dim=\"options\")\n",
    "    all_opts_var = postprocessing(all_opts_var, scenario)\n",
    "    dataset_var.append(all_opts_var)\n",
    "    \n",
    "    # mean\n",
    "    all_opts_mean = all_opts.mean(dim=\"options\")\n",
    "    all_opts_mean = postprocessing(all_opts_mean, scenario)\n",
    "    dataset_mean.append(all_opts_mean)\n",
    "    \n",
    "dataset_mean = pd.concat(dataset_mean)\n",
    "dataset_mean = pd.concat([dataset_mean_hist, dataset_mean]).reset_index()\n",
    "\n",
    "dataset_var  = pd.concat(dataset_var)\n",
    "dataset_var  = pd.concat([dataset_var_hist, dataset_var]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da6d41-13cf-49fe-aae7-e08cb212cc0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_replace = {\"scenario\": {\"historical\":'Historical', \"ct_random\":'Commitment run', \"ssp126\":'SSP 1-2.6', \"ssp245\":'SSP 2-4.5', \"ssp370\":'SSP 3-7.0', \"ssp585\":'SSP 5-8.5'}}\n",
    "\n",
    "dataset_mean = dataset_mean.replace(dict_replace)\n",
    "dataset_var  = dataset_var.replace(dict_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e0bc3-3491-4e43-ba3d-0257fcb0cee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenarios   = [\"Historical\", \"Commitment run\", \"SSP 1-2.6\", \"SSP 2-4.5\", \"SSP 3-7.0\", \"SSP 5-8.5\"]\n",
    "scen_colors = {\"Historical\":\"rgba(0, 0, 0, 0.8)\", \"Commitment run\":\"rgba(0, 0, 0, 0.5)\", \"SSP 1-2.6\":cl[0], \"SSP 2-4.5\":cl[2], \"SSP 3-7.0\":cl[1], \"SSP 5-8.5\":cl[3]}\n",
    "shaded_colors = {\"Historical\":\"rgba(0, 0, 0, 0.15)\", \"SSP 1-2.6\": \"rgba(31, 119, 180,0.15)\", \"SSP 5-8.5\":\"rgba(214, 39, 40, 0.15)\"}\n",
    "\n",
    "basins_id  = ['PPY', 'PCA','NPI-E','NPI-W','SPI-N', 'SPI-C', 'SPI-S', 'GCN', 'CDI']\n",
    "\n",
    "fig    = make_subplots(rows=9, cols=3, horizontal_spacing = 0.05, vertical_spacing = 0.01, \n",
    "                       shared_xaxes= True, shared_yaxes= False, row_titles = basins_id,\n",
    "                       subplot_titles= [\"Total runoff (m<sup>3</sup> s<sup>-1</sup>)\", \"Melt on glacier (m<sup>3</sup> s<sup>-1</sup>)\", \"Ratio\"])\n",
    "\n",
    "for x in range(0,9):\n",
    "    for y in range(0,3):\n",
    "        for t in range(0,6):\n",
    "             \n",
    "            # time series for each subplot and scenario\n",
    "            time_series_id    = dataset_mean[dataset_mean.rgi_id == basins_id[x]][dataset_mean.scenario == scenarios[t]]\n",
    "            time_series_sd_id = dataset_var[dataset_var.rgi_id == basins_id[x]][dataset_var.scenario == scenarios[t]]    \n",
    "            \n",
    "            if x==0 and y==0: # legend only for first plot\n",
    "        \n",
    "                fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.iloc[:,y+3], \n",
    "                                         mode='lines', name= scenarios[t], \n",
    "                                         line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=True, legendgroup=t), row=x+1, col=y+1)\n",
    "                \n",
    "                if t == 0 or t == 2 or t >= 5: # uncertainty: +-1 sd\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]+time_series_sd_id.iloc[:,y+3]), \n",
    "                                             line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup='g1'), row=x+1, col=y+1)\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]-time_series_sd_id.iloc[:,y+3]), \n",
    "                                             line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "            else:\n",
    "                # mean value\n",
    "                fig.add_trace(go.Scatter(x=time_series_id.time, y=time_series_id.iloc[:,y+3], mode='lines', name= scenarios[t], \n",
    "                                         line=dict(color=scen_colors[scenarios[t]], width = 1.5), showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "                if t == 0 or t == 2 or t >= 5: # uncertainty: +-1 sd# uncertainty: +-1 sd\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]+time_series_sd_id.iloc[:,y+3]), \n",
    "                                             line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "                    fig.add_trace(go.Scatter(x=time_series_sd_id.time, y=(time_series_id.iloc[:,y+3]-time_series_sd_id.iloc[:,y+3]), \n",
    "                                             line=dict(width=0), fillcolor=shaded_colors[scenarios[t]], fill='tonexty', showlegend=False, legendgroup=t), row=x+1, col=y+1)\n",
    "\n",
    "#  some tweaks\n",
    "for x in range(0,9):\n",
    "    for y in range(0,3):                \n",
    "        fig.update_yaxes(tickformat=\".0%\", dtick = 0.2, range = [0.1, 0.75], row=x+1, col=3)\n",
    "\n",
    "        \n",
    "fig.update_yaxes(dtick = 30 , row=1, col=1) \n",
    "fig.update_yaxes(dtick = 100, row=3, col=1) \n",
    "fig.update_yaxes(dtick = 500, row=6, col=1)  \n",
    "fig.update_yaxes(dtick = 200, row=7, col=1)  \n",
    "fig.update_yaxes(dtick = 150, row=9, col=1)  \n",
    "fig.update_yaxes(dtick = 300, row=5, col=2) \n",
    "fig.update_yaxes(dtick = 500, row=6, col=2) \n",
    "\n",
    "\n",
    "fig.update_yaxes(ticks=\"outside\", griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", showline = True, linecolor = 'black', linewidth = 0.2, mirror=True, tickangle = -90)\n",
    "fig.update_xaxes(ticks=\"outside\", griddash = \"dot\", gridcolor = \"rgba(255,255,255,0.8)\", showline = True, linecolor = 'black', linewidth = 0.2, mirror=True, dtick = 20)\n",
    "fig.update_layout(legend=dict(yanchor=\"top\", y=-0.02, xanchor=\"left\", x=0.15, orientation=\"h\", bgcolor = 'rgba(0,0,0,0.0)'))\n",
    "fig.update_layout(height=1200, width=1050, template = \"seaborn\", margin = dict(l=20, r=20, b=20, t=20), hovermode = False)\n",
    "\n",
    "# save figure \n",
    "fig.write_image(\"/home/rooda/Dropbox/Patagonia/MS2 Results/Figure_S2_hydro_projections.png\", scale=4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edea097-999f-4700-a18d-d938c037ccef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
