{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546609a9-0940-419c-ae28-cac52ea2ec11",
   "metadata": {},
   "source": [
    "# Partioning the evolution of uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import xarray as xr \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from oggm import utils\n",
    "from glob import glob\n",
    "\n",
    "# variables to analize\n",
    "variables        = ['melt_off_glacier', 'melt_on_glacier', 'liq_prcp_off_glacier', 'liq_prcp_on_glacier', 'volume', 'area']\n",
    "variables_final  = ['total_runoff','melt_on_glacier', 'smb']\n",
    "\n",
    "mods = glob(\"/home/rooda/OGGM_results/new/*/\", recursive = True)\n",
    "os.chdir(\"/home/rooda/Dropbox/Patagonia/MS2 Results/\")\n",
    "\n",
    "# historical \n",
    "outlines = [\"RGI6\", \"RGI7\"]\n",
    "volume   = [\"M22\", \"F19\"]\n",
    "climate  = [\"PMET\", \"CR2MET\", \"ERA5\",\"MSWEP\"]\n",
    "\n",
    "#future\n",
    "gcms = [\"ACCESS-CM2\", \"BCC-CSM2-MR\", \"CMCC-ESM2\", \"FGOALS-f3-L\", \"GFDL-ESM4\", \"CMCC-CM2-SR5\", \"KACE-1-0-G\", \"MPI-ESM1-2-HR\", \"MRI-ESM2-0\", \"MIROC6\"]\n",
    "ssps = [\"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"]\n",
    "bcms = [\"MVA\", \"DQM\", \"MBC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e8ce5-9cae-42de-8be3-873b622cdc37",
   "metadata": {},
   "source": [
    "## Ids for each glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a2021-64c5-429b-acd7-7098f13b8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGI6_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI7_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI7_v2.shp\")\n",
    "RGI6_ids = RGI6_ids[RGI6_ids.area_km2 > 7][[\"RGIId\", \"Zone\"]]\n",
    "RGI7_ids = RGI7_ids[RGI7_ids.area_km2 > 7]\n",
    "\n",
    "# RGI6 doesnt have IDs yet \n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'Zone' : 'Zone'})\n",
    "\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"Zone\"]]\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")\n",
    "\n",
    "dict_zone = {1:'PPY', 2:'PCA', 3:'NPI-E', 4:'NPI-W', 5:'SPI-N', 6:'SPI-C', 7:'SPI-S', 8:'GCN', 9:'CDI'}\n",
    "ids = ids.replace({\"Zone\": dict_zone})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696afb8b-3ac2-41b9-9da2-e5331af82763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds): # remove unnecessary variables and coordinates\n",
    "    return ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])[variables]\n",
    "\n",
    "def hydro_variables(ds): # calculate total_runoff, melt_on_glacier and smb\n",
    "    ds[\"total_runoff\"] = (ds.melt_off_glacier + ds.melt_on_glacier + ds.liq_prcp_off_glacier + ds.liq_prcp_on_glacier)*1e-9\n",
    "    ds[\"melt_on_glacier\"] = (ds.melt_on_glacier)*1e-9\n",
    "    ds[\"smb\"] = (ds.volume.diff(dim = \"time\") * 900 / ds.area)\n",
    "    return ds[variables_final]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b503ce03-14e1-4d7f-ae65-b0fc99a1bbc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3916e1a-413f-48b7-b8b5-31afc4a32ad2",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b50f86-fac6-4d08-b056-94c77cb77555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_combs = glob(\"/home/rooda/OGGM_results/new/*/run_output_*.nc\", recursive = True)\n",
    "all_opts   = xr.open_mfdataset(all_combs, combine='nested', concat_dim=\"options\", chunks=\"auto\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "# assing zone to each glacier and aggregate the result \n",
    "ids_subset = ids[ids.index.isin(all_opts.rgi_id.to_pandas().tolist())]\n",
    "all_opts   = all_opts.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "all_opts   = all_opts.groupby('rgi_id').sum()\n",
    "\n",
    "all_opts   = all_opts.chunk(\"auto\")\n",
    "all_opts   = hydro_variables(all_opts)\n",
    "\n",
    "all_opts = all_opts.isel(time = slice(0, -1))\n",
    "all_opts = all_opts.std(dim=\"options\")\n",
    "all_opts = all_opts.to_dataframe()\n",
    "all_opts = all_opts.to_csv(\"variance_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4695fa-e3ea-43d8-b664-689a18725a21",
   "metadata": {},
   "source": [
    "## Scenarios (SSPs) and  natural variability (2020-2030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c182c-2f00-4985-b7a0-a3ccff6fe560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = slice(\"2020-01-01\", \"2029-31-12\")\n",
    "all_ssps = []\n",
    "\n",
    "for mod in mods: \n",
    "    for gcm in gcms: \n",
    "        for bcm in bcms:\n",
    "            files  = glob(mod + \"*\" + gcm + \"_*\" +  bcm + \"*.nc\")\n",
    "            ssp_i  = xr.open_mfdataset(files, combine='nested', concat_dim=\"options\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "            # assing zone to each glacier and aggregate the result \n",
    "            ids_subset = ids[ids.index.isin(ssp_i.rgi_id.to_pandas().tolist())]\n",
    "            ssp_i   = ssp_i.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "            ssp_i   = ssp_i.groupby('rgi_id').sum()\n",
    " \n",
    "            ssp_i   = hydro_variables(ssp_i)\n",
    "            ssp_i = ssp_i.std(dim=\"options\")\n",
    "            all_ssps.append(ssp_i)\n",
    "            \n",
    "all_ssps = xr.concat(all_ssps, dim='ssp')\n",
    "all_ssps = all_ssps.isel(time = slice(0, -1))\n",
    "\n",
    "# natural variability\n",
    "all_ssps_nv = all_ssps.sel(time = period)\n",
    "all_ssps_nv = all_ssps_nv.mean(dim=\"ssp\")\n",
    "all_ssps_nv = all_ssps_nv.mean(dim=\"time\")\n",
    "all_ssps_nv = all_ssps_nv.to_dataframe().to_csv(\"variance_ssp_nv.csv\")\n",
    "\n",
    "# scenarios\n",
    "all_ssps = all_ssps.mean(dim=\"ssp\")\n",
    "all_ssps = all_ssps.to_dataframe().to_csv(\"variance_ssp_scenarios.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58d794-e27e-4b80-a2d0-b83e8967b7db",
   "metadata": {},
   "source": [
    "## Models (GCMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52315b85-4306-4ba7-a4c6-dfd13af3022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gcms = []\n",
    "\n",
    "for mod in mods: \n",
    "    for ssp in ssps: \n",
    "        for bcm in bcms:\n",
    "                files = glob(mod + \"*\" + ssp + \"_\" + bcm + \"*.nc\")\n",
    "                gcm_i = xr.open_mfdataset(files, combine='nested', concat_dim=\"options\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "                # assing zone to each glacier and aggregate the result \n",
    "                ids_subset = ids[ids.index.isin(gcm_i.rgi_id.to_pandas().tolist())]\n",
    "                gcm_i   = gcm_i.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "                gcm_i   = gcm_i.groupby('rgi_id').sum()\n",
    "                \n",
    "                gcm_i   = hydro_variables(gcm_i)\n",
    "                gcm_i = gcm_i.std(dim=\"options\")\n",
    "                all_gcms.append(gcm_i)\n",
    "    \n",
    "all_gcms = xr.concat(all_gcms, dim='gcm')\n",
    "all_gcms = all_gcms.isel(time = slice(0, -1))\n",
    "all_gcms = all_gcms.mean(dim=\"gcm\")\n",
    "all_gcms = all_gcms.to_dataframe().to_csv(\"variance_gcms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e98c6-eed1-468f-b291-2519829a6ba8",
   "metadata": {},
   "source": [
    "## Model set-up (only climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43f063-1e3b-4cf4-bfcf-b357d84fa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_climate = []\n",
    "\n",
    "for rgi in outlines: \n",
    "    for vol in volume: \n",
    "        for gcm in gcms: \n",
    "            for ssp in ssps: \n",
    "                for bcm in bcms:\n",
    "                    path_i = glob(os.path.dirname(os.path.normpath(mods[0])) + \"/*\"+ rgi +\"*_\"+ vol +\"*/*\" + gcm + \"_\" + ssp + \"_\" + bcm + \".nc\")\n",
    "                    mod_i  = xr.open_mfdataset(path_i, combine='nested', concat_dim=\"options\", parallel=True, preprocess=preprocess)\n",
    "\n",
    "                    # assing zone to each glacier and aggregate the result \n",
    "                    ids_subset = ids[ids.index.isin(mod_i.rgi_id.to_pandas().tolist())]   \n",
    "                    mod_i   = mod_i.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "                    mod_i   = mod_i.groupby('rgi_id').sum()\n",
    "\n",
    "                    mod_i   = hydro_variables(mod_i)\n",
    "                    mod_i = mod_i.std(dim=\"options\")\n",
    "                    all_climate.append(mod_i)\n",
    "\n",
    "all_climate = xr.concat(all_climate, dim='climate')\n",
    "all_climate = all_climate.isel(time = slice(0, -1))\n",
    "all_climate = all_climate.mean(dim=\"climate\")\n",
    "all_climate = all_climate.to_dataframe().to_csv(\"variance_climate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e85c87-dc41-4886-a283-bd663b50d3c7",
   "metadata": {},
   "source": [
    "## Model set-up (geometry/volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e061e7-1042-42c6-95a3-f09c28b3f636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_mods = []\n",
    "\n",
    "for cli in climate:\n",
    "    for gcm in gcms: \n",
    "        for ssp in ssps: \n",
    "            for bcm in bcms:\n",
    "                path_i = glob(os.path.dirname(os.path.normpath(mods[0])) + \"/*\" + cli + \"*/*\" + gcm + \"_\" + ssp + \"_\" + bcm + \".nc\")\n",
    "                mod_i  = xr.open_mfdataset(path_i, combine='nested', concat_dim=\"options\")[variables]\n",
    "                mod_i  = mod_i.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])\n",
    "\n",
    "                # assing zone to each glacier and aggregate the result \n",
    "                ids_subset = ids[ids.index.isin(mod_i.rgi_id.to_pandas().tolist())]   \n",
    "                mod_i = mod_i.assign_coords(rgi_id = ids_subset.Zone.tolist())\n",
    "                mod_i = mod_i.groupby('rgi_id').sum()\n",
    "\n",
    "                mod_i = hydro_variables(mod_i)\n",
    "                mod_i = mod_i.std(dim=\"options\")\n",
    "                all_mods.append(mod_i)\n",
    "\n",
    "all_mods = xr.concat(all_mods, dim='mod')\n",
    "all_mods = all_mods.isel(time = slice(0, -1))\n",
    "all_mods = all_mods.mean(dim=\"mod\")\n",
    "all_mods = all_mods.to_dataframe().to_csv(\"variance_geometry.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
